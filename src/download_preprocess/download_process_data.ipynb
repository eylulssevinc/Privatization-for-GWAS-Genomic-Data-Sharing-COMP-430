{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f722a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/erkmenerken/Desktop/430_project\n",
      "Genotype dir : /Users/erkmenerken/Desktop/430_project/data/raw/hapmap/genotypes\n",
      "Phasing dir  : /Users/erkmenerken/Desktop/430_project/data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED\n",
      "Phasing meta : /Users/erkmenerken/Desktop/430_project/data/raw/hapmap/phasing/HapMap3_r2\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# project_root = 430_project/\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if PROJECT_ROOT.name != \"430_project\":\n",
    "\n",
    "    for parent in Path.cwd().parents:\n",
    "        if parent.name == \"430_project\":\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "HAPMAP_RAW = DATA_RAW / \"hapmap\"\n",
    "\n",
    "GENO_DIR = HAPMAP_RAW / \"genotypes\"\n",
    "PHASE_DIR = HAPMAP_RAW / \"phasing\" / \"HapMap3_r2\" / \"CEU\" / \"UNRELATED\"\n",
    "PHASE_META_DIR = HAPMAP_RAW / \"phasing\" / \"HapMap3_r2\"\n",
    "\n",
    "for d in [GENO_DIR, PHASE_DIR, PHASE_META_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Genotype dir :\", GENO_DIR)\n",
    "print(\"Phasing dir  :\", PHASE_DIR)\n",
    "print(\"Phasing meta :\", PHASE_META_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32ffb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Manifest entries: 5\n",
      "- CEU genotypes chr2 (unphased) -> data/raw/hapmap/genotypes/genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz\n",
      "- CEU genotypes chr10 (unphased) -> data/raw/hapmap/genotypes/genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz\n",
      "- CEU phased haplotypes chr2 (UNRELATED) -> data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz\n",
      "- CEU phased haplotypes chr10 (UNRELATED) -> data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz\n",
      "- HapMap3 r2 SNP meta (.info) -> data/raw/hapmap/phasing/HapMap3_r2/hapmap3_r2_b36_fwd.consensus.qc.poly.info\n"
     ]
    }
   ],
   "source": [
    "# Sources used:\n",
    "# - Genotypes (CEU, non-redundant, b36, forward): chr2 + chr10\n",
    "# - Phased haplotypes (HapMap3 r2, CEU, UNRELATED): chr2 + chr10\n",
    "# - Small meta file in HapMap3 r2 directory (.info)\n",
    "\n",
    "MANIFEST = [\n",
    "    {\n",
    "        \"name\": \"CEU genotypes chr2 (unphased)\",\n",
    "        \"url\": \"https://ftp.ncbi.nlm.nih.gov/hapmap/genotypes/latest_phaseII+III_ncbi_b36/forward/non-redundant/genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz\",\n",
    "        \"dst\": GENO_DIR / \"genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CEU genotypes chr10 (unphased)\",\n",
    "        \"url\": \"https://ftp.ncbi.nlm.nih.gov/hapmap/genotypes/latest_phaseII+III_ncbi_b36/forward/non-redundant/genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz\",\n",
    "        \"dst\": GENO_DIR / \"genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CEU phased haplotypes chr2 (UNRELATED)\",\n",
    "        \"url\": \"https://ftp.ncbi.nlm.nih.gov/hapmap/phasing/2009-02_phaseIII/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz\",\n",
    "        \"dst\": PHASE_DIR / \"hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CEU phased haplotypes chr10 (UNRELATED)\",\n",
    "        \"url\": \"https://ftp.ncbi.nlm.nih.gov/hapmap/phasing/2009-02_phaseIII/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz\",\n",
    "        \"dst\": PHASE_DIR / \"hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"HapMap3 r2 SNP meta (.info)\",\n",
    "        \"url\": \"https://ftp.ncbi.nlm.nih.gov/hapmap/phasing/2009-02_phaseIII/HapMap3_r2/hapmap3_r2_b36_fwd.consensus.qc.poly.info\",\n",
    "        \"dst\": PHASE_META_DIR / \"hapmap3_r2_b36_fwd.consensus.qc.poly.info\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\" Manifest entries: {len(MANIFEST)}\")\n",
    "for x in MANIFEST:\n",
    "    print(\"-\", x[\"name\"], \"->\", x[\"dst\"].relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87437182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def download_file(url: str, dst: Path, overwrite: bool = False, chunk_size: int = 1024 * 1024) -> None:\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if dst.exists() and not overwrite:\n",
    "        size_bytes = dst.stat().st_size\n",
    "        if size_bytes > 0:\n",
    "            print(f\"  Already exists, skipping: {dst.name} ({size_bytes/1e6:.2f} MB)\")\n",
    "            return\n",
    "        print(f\"  Existing file is empty, re-downloading: {dst.name}\")\n",
    "\n",
    "    tmp = dst.with_suffix(dst.suffix + \".part\")\n",
    "\n",
    "    print(f\"  Downloading: {url}\")\n",
    "    print(f\" Saving to  : {dst}\")\n",
    "\n",
    "    req = urllib.request.Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    with urllib.request.urlopen(req) as resp:\n",
    "        total = resp.headers.get(\"Content-Length\")\n",
    "        total = int(total) if total is not None else None\n",
    "\n",
    "        with open(tmp, \"wb\") as f, tqdm(\n",
    "            total=total, unit=\"B\", unit_scale=True, unit_divisor=1024, desc=dst.name\n",
    "        ) as pbar:\n",
    "            while True:\n",
    "                chunk = resp.read(chunk_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                f.write(chunk)\n",
    "                pbar.update(len(chunk))\n",
    "\n",
    "    os.replace(tmp, dst)  # atomic move\n",
    "    print(f\" Done: {dst.name} ({dst.stat().st_size/1e6:.2f} MB)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b8402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting HapMap downloads...\n",
      "\n",
      "=== CEU genotypes chr2 (unphased) ===\n",
      "  Already exists, skipping: genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz (21.10 MB)\n",
      "=== CEU genotypes chr10 (unphased) ===\n",
      "  Already exists, skipping: genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz (13.63 MB)\n",
      "=== CEU phased haplotypes chr2 (UNRELATED) ===\n",
      "  Already exists, skipping: hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz (1.80 MB)\n",
      "=== CEU phased haplotypes chr10 (UNRELATED) ===\n",
      "  Already exists, skipping: hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz (1.13 MB)\n",
      "=== HapMap3 r2 SNP meta (.info) ===\n",
      "  Already exists, skipping: hapmap3_r2_b36_fwd.consensus.qc.poly.info (0.03 MB)\n",
      " All requested HapMap files are present in data/raw/hapmap/.\n"
     ]
    }
   ],
   "source": [
    "print(\" Starting HapMap downloads...\\n\")\n",
    "\n",
    "for item in MANIFEST:\n",
    "    print(f\"=== {item['name']} ===\")\n",
    "    download_file(item[\"url\"], item[\"dst\"], overwrite=False)\n",
    "\n",
    "print(\" All requested HapMap files are present in data/raw/hapmap/.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1537923f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Downloaded files:\n",
      "data/raw/hapmap/genotypes/genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz - 21.10 MB\n",
      "data/raw/hapmap/genotypes/genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz - 13.63 MB\n",
      "data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz - 1.80 MB\n",
      "data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz - 1.13 MB\n",
      "data/raw/hapmap/phasing/HapMap3_r2/hapmap3_r2_b36_fwd.consensus.qc.poly.info - 0.03 MB\n"
     ]
    }
   ],
   "source": [
    "def human_mb(n_bytes: int) -> str:\n",
    "    return f\"{n_bytes/1e6:.2f} MB\"\n",
    "\n",
    "print(\" Downloaded files:\")\n",
    "for item in MANIFEST:\n",
    "    p = item[\"dst\"]\n",
    "    if p.exists():\n",
    "        print(p.relative_to(PROJECT_ROOT), \"-\", human_mb(p.stat().st_size))\n",
    "    else:\n",
    "        print(\"MISSING:\", p.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fdf0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Project root: /Users/erkmenerken/Desktop/430_project\n",
      " Raw HapMap  : /Users/erkmenerken/Desktop/430_project/data/raw/hapmap\n",
      " Genotypes   : /Users/erkmenerken/Desktop/430_project/data/raw/hapmap/genotypes\n",
      " Phasing     : /Users/erkmenerken/Desktop/430_project/data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED\n",
      " Processed   : /Users/erkmenerken/Desktop/430_project/data/processed/hapmap\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_project_root(name=\"430_project\") -> Path:\n",
    "    cwd = Path.cwd()\n",
    "    if cwd.name == name:\n",
    "        return cwd\n",
    "    for p in [cwd] + list(cwd.parents):\n",
    "        if p.name == name:\n",
    "            return p\n",
    "    raise RuntimeError(f\"Could not find project root folder named '{name}' from {cwd}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(\"430_project\")\n",
    "\n",
    "RAW_HAPMAP = PROJECT_ROOT / \"data\" / \"raw\" / \"hapmap\"\n",
    "GENO_DIR   = RAW_HAPMAP / \"genotypes\"\n",
    "PHASE_DIR  = RAW_HAPMAP / \"phasing\" / \"HapMap3_r2\" / \"CEU\" / \"UNRELATED\"\n",
    "\n",
    "PROC_DIR   = PROJECT_ROOT / \"data\" / \"processed\" / \"hapmap\"\n",
    "REGION_DIR = PROC_DIR / \"regions\"\n",
    "BLOCK_DIR  = PROC_DIR / \"blocks\"\n",
    "COHORT_DIR = PROC_DIR / \"cohorts\"\n",
    "\n",
    "for d in [PROC_DIR, REGION_DIR, BLOCK_DIR, COHORT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\" Project root:\", PROJECT_ROOT)\n",
    "print(\" Raw HapMap  :\", RAW_HAPMAP)\n",
    "print(\" Genotypes   :\", GENO_DIR)\n",
    "print(\" Phasing     :\", PHASE_DIR)\n",
    "print(\" Processed   :\", PROC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bd40fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Peeking: genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz\n",
      "  Line 1: rs# alleles chrom pos strand assembly# center protLSID assayLSID panelLSID QCcode NA06984 NA06985 NA06986 NA06989 NA06991 NA06993 NA06994 NA06995 NA06997 NA07000 NA07014 NA07019 NA07022 NA07029 NA07031 NA07034 NA07037 NA\n",
      "  Line 2: rs10171150 A/G chr2 2091 + ncbi_b36 mcgill-gqic urn:LSID:illumina.hapmap.org:Protocol:Golden_Gate_1.0.0:1 urn:LSID:mcgill-gqic.hapmap.org:Assay:810448:1 urn:lsid:dcc.hapmap.org:Panel:CEPH-30-trios:1 QC+ NN GG NN NN GG GG\n",
      "\n",
      "ðŸ”Ž Peeking: genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz\n",
      "  Line 1: rs# alleles chrom pos strand assembly# center protLSID assayLSID panelLSID QCcode NA06984 NA06985 NA06986 NA06989 NA06991 NA06993 NA06994 NA06995 NA06997 NA07000 NA07014 NA07019 NA07022 NA07029 NA07031 NA07034 NA07037 NA\n",
      "  Line 2: rs11511647 C/T chr10 62765 + ncbi_b36 sanger urn:lsid:illumina.hapmap.org:Protocol:Golden_Gate_1.0.0:1 urn:lsid:sanger.hapmap.org:Assay:4310385:1 urn:lsid:dcc.hapmap.org:Panel:CEPH-30-trios:1 QC+ NN CT NN NN CT CT CT NN\n",
      "\n",
      "ðŸ”Ž Peeking: hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz\n",
      "  Line 1: rsID position_b36 NA06989_A NA06989_B NA10850_A NA10850_B NA06984_A NA06984_B NA11917_A NA11917_B NA12282_A NA12282_B NA12283_A NA12283_B NA11918_A NA11918_B NA12413_A NA12413_B NA07056_A NA07056_B NA12044_A NA12044_B NA\n",
      "  Line 2: rs10181821 5703 A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A\n",
      "\n",
      "ðŸ”Ž Peeking: hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz\n",
      "  Line 1: rsID position_b36 NA06989_A NA06989_B NA10850_A NA10850_B NA06984_A NA06984_B NA11917_A NA11917_B NA12282_A NA12282_B NA12283_A NA12283_B NA11918_A NA11918_B NA12413_A NA12413_B NA07056_A NA07056_B NA12044_A NA12044_B NA\n",
      "  Line 2: rs12255619 88481 A C A A A A A A A A A C A A A A A A A A A A A A A A A A A A A A A A\n",
      "\n",
      " If the header looks like: rs# alleles chrom pos ... QCcode NA06984 ... then weâ€™re good.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "geno_chr2  = GENO_DIR / \"genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz\"\n",
    "geno_chr10 = GENO_DIR / \"genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz\"\n",
    "phase_chr2  = PHASE_DIR / \"hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz\"\n",
    "phase_chr10 = PHASE_DIR / \"hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz\"\n",
    "\n",
    "def peek_gz(path, n_lines=2, maxchars=220):\n",
    "    print(f\"\\nðŸ”Ž Peeking: {path.name}\")\n",
    "    with gzip.open(path, \"rt\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for i in range(n_lines):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            print(f\"  Line {i+1}: {line[:maxchars].rstrip()}\")\n",
    "\n",
    "for p in [geno_chr2, geno_chr10, phase_chr2, phase_chr10]:\n",
    "    if p.exists():\n",
    "        peek_gz(p, n_lines=2)\n",
    "    else:\n",
    "        print(\" Missing:\", p)\n",
    "\n",
    "print(\"\\n If the header looks like: rs# alleles chrom pos ... QCcode NA06984 ... then weâ€™re good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bbbc1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading rs# + pos from genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz (whitespace-separated)...\n",
      " Loaded 329831 SNP positions.\n",
      " Reading rs# + pos from genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz (whitespace-separated)...\n",
      " Loaded 211711 SNP positions.\n",
      "\n",
      " Proposal-style windows selected:\n",
      "chr2 (5Mb, ~311 SNPs): {'start_bp': 242050505, 'end_bp': 247050505, 'snps_in_window': 311, 'end_pos_actual': 242742878, 'total_snps_chr': 329831, 'min_pos': 2091, 'max_pos': 242742878}\n",
      "chr10 (1Mb, ~610 SNPs): {'start_bp': 38322261, 'end_bp': 39322261, 'snps_in_window': 610, 'end_pos_actual': 39194226, 'total_snps_chr': 211711, 'min_pos': 62765, 'max_pos': 135373179}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_positions_rsids(geno_path):\n",
    "    print(f\" Reading rs# + pos from {geno_path.name} (whitespace-separated)...\")\n",
    "    df = pd.read_csv(\n",
    "        geno_path,\n",
    "        sep=r\"\\s+\",\n",
    "        engine=\"python\",\n",
    "        compression=\"gzip\",\n",
    "        usecols=[\"rs#\", \"pos\"],\n",
    "        dtype={\"rs#\": str, \"pos\": int},\n",
    "    )\n",
    "    df = df.dropna().sort_values(\"pos\").reset_index(drop=True)\n",
    "    print(f\" Loaded {len(df)} SNP positions.\")\n",
    "    return df\n",
    "\n",
    "def choose_window_by_bp(df_pos, window_bp, target_snps):\n",
    "    pos = df_pos[\"pos\"].to_numpy(np.int64)\n",
    "    n = len(pos)\n",
    "    ends = np.searchsorted(pos, pos + window_bp, side=\"right\")\n",
    "    counts = ends - np.arange(n)\n",
    "\n",
    "    diff = np.abs(counts - target_snps)\n",
    "    best_i = int(np.argmin(diff))\n",
    "\n",
    "    start = int(pos[best_i])\n",
    "    end = int(start + window_bp)\n",
    "    count = int(counts[best_i])\n",
    "    end_idx = int(ends[best_i] - 1)\n",
    "    end_pos_actual = int(pos[end_idx]) if end_idx >= best_i else start\n",
    "\n",
    "    return {\n",
    "        \"start_bp\": start,\n",
    "        \"end_bp\": end,\n",
    "        \"snps_in_window\": count,\n",
    "        \"end_pos_actual\": end_pos_actual,\n",
    "        \"total_snps_chr\": int(n),\n",
    "        \"min_pos\": int(pos[0]),\n",
    "        \"max_pos\": int(pos[-1]),\n",
    "    }\n",
    "\n",
    "df2  = load_positions_rsids(geno_chr2)\n",
    "df10 = load_positions_rsids(geno_chr10)\n",
    "\n",
    "chr2_plan  = choose_window_by_bp(df2,  window_bp=5_000_000, target_snps=311)\n",
    "chr10_plan = choose_window_by_bp(df10, window_bp=1_000_000, target_snps=610)\n",
    "\n",
    "print(\"\\n Proposal-style windows selected:\")\n",
    "print(\"chr2 (5Mb, ~311 SNPs):\", chr2_plan)\n",
    "print(\"chr10 (1Mb, ~610 SNPs):\", chr10_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff17848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "MISSING_TOKENS = {\"\", \"NN\", \"NA\", \"N\", \"00\", \"--\", \"??\"}\n",
    "\n",
    "def _find_sample_columns(columns):\n",
    "    cols = list(columns)\n",
    "    if \"QCcode\" in cols:\n",
    "        qc_idx = cols.index(\"QCcode\")\n",
    "        return cols[:qc_idx + 1], cols[qc_idx + 1:]\n",
    "    # Fallback (rarely needed for HapMap)\n",
    "    return cols[:11], cols[11:]\n",
    "\n",
    "def genotype_row_to_minor_counts(geno_strs, allele_a, allele_b):\n",
    "    \"\"\"\n",
    "    Convert HapMap genotype strings (e.g., 'AA', 'AG', 'GG', 'NN') to\n",
    "    minor-allele counts in {0,1,2} with -1 for missing.\n",
    "\n",
    "    Minor allele is determined per SNP by observed allele counts in the row.\n",
    "    \"\"\"\n",
    "    g = np.asarray(geno_strs, dtype=object)\n",
    "    g = np.array([x.strip() if isinstance(x, str) else \"\" for x in g], dtype=object)\n",
    "\n",
    "    missing = np.zeros(len(g), dtype=bool)\n",
    "    for t in MISSING_TOKENS:\n",
    "        missing |= (g == t)\n",
    "\n",
    "    # valid genotype strings are length 2 (e.g. \"AG\")\n",
    "    valid = (~missing) & np.array([len(x) == 2 for x in g], dtype=bool)\n",
    "\n",
    "    # count allele occurrences among valid entries\n",
    "    a_count = 0\n",
    "    b_count = 0\n",
    "    for x in g[valid]:\n",
    "        a_count += (x[0] == allele_a) + (x[1] == allele_a)\n",
    "        b_count += (x[0] == allele_b) + (x[1] == allele_b)\n",
    "\n",
    "    # choose minor allele (ties deterministic)\n",
    "    if a_count < b_count:\n",
    "        minor, major = allele_a, allele_b\n",
    "    elif b_count < a_count:\n",
    "        minor, major = allele_b, allele_a\n",
    "    else:\n",
    "        minor, major = allele_b, allele_a\n",
    "\n",
    "    out = np.full(len(g), -1, dtype=np.int8)\n",
    "    for i, x in enumerate(g):\n",
    "        if (not isinstance(x, str)) or (x in MISSING_TOKENS) or len(x) != 2:\n",
    "            continue\n",
    "        out[i] = np.int8((x[0] == minor) + (x[1] == minor))\n",
    "\n",
    "    return out, minor, major\n",
    "\n",
    "def parse_genotypes_window(geno_path, start_bp, end_bp, chunksize=2000):\n",
    "    \"\"\"\n",
    "    Parses HapMap whitespace-separated genotype .txt.gz file and extracts SNPs\n",
    "    within [start_bp, end_bp]. Returns:\n",
    "      G (M x N): int8 minor allele counts, missing=-1\n",
    "      sample_ids (M,)\n",
    "      snp_ids (N,)\n",
    "      positions (N,)\n",
    "      minor_alleles (N,)\n",
    "      major_alleles (N,)\n",
    "    \"\"\"\n",
    "    print(f\"\\n Parsing genotypes from {geno_path.name}\")\n",
    "    print(f\"   Window: [{start_bp}, {end_bp}] bp (inclusive)\")\n",
    "\n",
    "    # Read header row only (detect columns + sample IDs)\n",
    "    header = pd.read_csv(\n",
    "        geno_path,\n",
    "        sep=r\"\\s+\",\n",
    "        engine=\"python\",\n",
    "        compression=\"gzip\",\n",
    "        nrows=1,\n",
    "        dtype=str\n",
    "    )\n",
    "    _, sample_cols = _find_sample_columns(header.columns)\n",
    "    sample_ids = np.array(sample_cols, dtype=object)\n",
    "    print(f\" Individuals detected: {len(sample_ids)}\")\n",
    "\n",
    "    G_cols, snp_ids, positions, minor_alleles, major_alleles = [], [], [], [], []\n",
    "\n",
    "    reader = pd.read_csv(\n",
    "        geno_path,\n",
    "        sep=r\"\\s+\",\n",
    "        engine=\"python\",\n",
    "        compression=\"gzip\",\n",
    "        dtype=str,\n",
    "        chunksize=chunksize,\n",
    "    )\n",
    "\n",
    "    kept = 0\n",
    "    for chunk in tqdm(reader, desc=f\"Reading {geno_path.name}\"):\n",
    "        # Filter by window using numeric positions\n",
    "        pos_int = pd.to_numeric(chunk[\"pos\"], errors=\"coerce\")\n",
    "        mask = (pos_int >= start_bp) & (pos_int <= end_bp)\n",
    "        chunk = chunk.loc[mask]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "        for _, row in chunk.iterrows():\n",
    "            rsid = row.get(\"rs#\", None)\n",
    "            alleles = row.get(\"alleles\", None)\n",
    "            pos = row.get(\"pos\", None)\n",
    "\n",
    "            if rsid is None or alleles is None or pos is None or \"/\" not in alleles:\n",
    "                continue\n",
    "\n",
    "            a, b = [x.strip() for x in alleles.split(\"/\", 1)]\n",
    "            if len(a) != 1 or len(b) != 1:\n",
    "                continue\n",
    "\n",
    "            geno_strs = row[sample_cols].values\n",
    "            counts, minor, major = genotype_row_to_minor_counts(geno_strs, a, b)\n",
    "\n",
    "            G_cols.append(counts)\n",
    "            snp_ids.append(rsid)\n",
    "            positions.append(int(pos))\n",
    "            minor_alleles.append(minor)\n",
    "            major_alleles.append(major)\n",
    "            kept += 1\n",
    "\n",
    "    if kept == 0:\n",
    "        raise RuntimeError(\"No SNPs were kept. Check start/end window values.\")\n",
    "\n",
    "    G = np.stack(G_cols, axis=1)  # (M, N)\n",
    "    positions = np.array(positions, dtype=np.int32)\n",
    "\n",
    "    # Sort by position (just in case)\n",
    "    order = np.argsort(positions)\n",
    "    G = G[:, order]\n",
    "    positions = positions[order]\n",
    "    snp_ids = np.array(snp_ids, dtype=object)[order]\n",
    "    minor_alleles = np.array(minor_alleles, dtype=object)[order]\n",
    "    major_alleles = np.array(major_alleles, dtype=object)[order]\n",
    "\n",
    "    print(f\" Kept SNPs: {G.shape[1]} | Individuals: {G.shape[0]}\")\n",
    "    print(f\" Missing rate: {float(np.mean(G == -1)):.4f}\")\n",
    "    print(f\" Kept position range: {int(positions.min())} .. {int(positions.max())}\")\n",
    "\n",
    "    return G, sample_ids, snp_ids, positions, minor_alleles, major_alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2b8decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Parsing genotypes from genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz\n",
      "   Window: [242050505, 247050505] bp (inclusive)\n",
      " Individuals detected: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading genotypes_chr2_CEU_r27_nr.b36_fwd.txt.gz: 165it [00:24,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kept SNPs: 311 | Individuals: 174\n",
      " Missing rate: 0.2843\n",
      " Kept position range: 242050505 .. 242742878\n",
      " Saved: data/processed/hapmap/regions/CEU_chr2_5Mb.npz\n",
      " Meta : data/processed/hapmap/regions/CEU_chr2_5Mb.meta.json\n",
      "\n",
      "\n",
      " Parsing genotypes from genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz\n",
      "   Window: [38322261, 39322261] bp (inclusive)\n",
      " Individuals detected: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading genotypes_chr10_CEU_r27_nr.b36_fwd.txt.gz: 106it [00:15,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kept SNPs: 610 | Individuals: 174\n",
      " Missing rate: 0.3864\n",
      " Kept position range: 38322261 .. 39194226\n",
      " Saved: data/processed/hapmap/regions/CEU_chr10_1Mb.npz\n",
      " Meta : data/processed/hapmap/regions/CEU_chr10_1Mb.meta.json\n",
      "\n",
      " Region extraction complete.\n",
      " Check: data/processed/hapmap/regions/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json, time\n",
    "\n",
    "def save_region(region_name, chrom, plan, G, sample_ids, snp_ids, positions, minor, major):\n",
    "    out_npz = REGION_DIR / f\"{region_name}.npz\"\n",
    "    out_meta = REGION_DIR / f\"{region_name}.meta.json\"\n",
    "\n",
    "    np.savez_compressed(\n",
    "        out_npz,\n",
    "        G=G.astype(np.int8),\n",
    "        sample_ids=sample_ids,\n",
    "        snp_ids=snp_ids,\n",
    "        positions=positions,\n",
    "        minor_alleles=minor,\n",
    "        major_alleles=major,\n",
    "        chrom=str(chrom),\n",
    "    )\n",
    "\n",
    "    meta = {\n",
    "        \"region_name\": region_name,\n",
    "        \"chrom\": str(chrom),\n",
    "        \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"window_start_bp\": int(plan[\"start_bp\"]),\n",
    "        \"window_end_bp\": int(plan[\"end_bp\"]),\n",
    "        \"snps_in_window\": int(G.shape[1]),\n",
    "        \"individuals\": int(G.shape[0]),\n",
    "        \"missing_rate\": float(np.mean(G == -1)),\n",
    "        \"note\": \"G is minor-allele count in {0,1,2}, missing=-1.\",\n",
    "    }\n",
    "    out_meta.write_text(json.dumps(meta, indent=2))\n",
    "\n",
    "    print(f\" Saved: {out_npz.relative_to(PROJECT_ROOT)}\")\n",
    "    print(f\" Meta : {out_meta.relative_to(PROJECT_ROOT)}\\n\")\n",
    "\n",
    "# chr2\n",
    "G2, ids2, rs2, pos2, min2, maj2 = parse_genotypes_window(geno_chr2, chr2_plan[\"start_bp\"], chr2_plan[\"end_bp\"])\n",
    "save_region(\"CEU_chr2_5Mb\", 2, chr2_plan, G2, ids2, rs2, pos2, min2, maj2)\n",
    "\n",
    "# chr10\n",
    "G10, ids10, rs10, pos10, min10, maj10 = parse_genotypes_window(geno_chr10, chr10_plan[\"start_bp\"], chr10_plan[\"end_bp\"])\n",
    "save_region(\"CEU_chr10_1Mb\", 10, chr10_plan, G10, ids10, rs10, pos10, min10, maj10)\n",
    "\n",
    "print(\" Region extraction complete.\")\n",
    "print(\" Check: data/processed/hapmap/regions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c6eb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created CEU control/test split\n",
      "   control n=139 | test n=35\n",
      " Saved: data/processed/hapmap/cohorts/ceu_control_test_split.json\n"
     ]
    }
   ],
   "source": [
    "def make_split(sample_ids, test_frac=0.2, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(sample_ids)\n",
    "    idx = np.arange(n)\n",
    "    rng.shuffle(idx)\n",
    "    n_test = int(round(test_frac * n))\n",
    "    test_idx = np.sort(idx[:n_test])\n",
    "    control_idx = np.sort(idx[n_test:])\n",
    "    return control_idx, test_idx\n",
    "\n",
    "control_idx, test_idx = make_split(ids2, test_frac=0.2, seed=0)\n",
    "\n",
    "cohorts = {\n",
    "    \"notes\": {\n",
    "        \"case_source\": \"PGP (TBD)\",\n",
    "        \"control_test_source\": \"HapMap CEU\",\n",
    "        \"split_seed\": 0,\n",
    "        \"test_frac\": 0.2\n",
    "    },\n",
    "    \"case\": {\"sample_ids\": [], \"indices_in_ceu_matrix\": []},\n",
    "    \"control\": {\n",
    "        \"sample_ids\": [str(ids2[i]) for i in control_idx],\n",
    "        \"indices_in_ceu_matrix\": control_idx.tolist()\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"sample_ids\": [str(ids2[i]) for i in test_idx],\n",
    "        \"indices_in_ceu_matrix\": test_idx.tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "out_path = COHORT_DIR / \"ceu_control_test_split.json\"\n",
    "out_path.write_text(json.dumps(cohorts, indent=2))\n",
    "\n",
    "print(\" Created CEU control/test split\")\n",
    "print(f\"   control n={len(control_idx)} | test n={len(test_idx)}\")\n",
    "print(\" Saved:\", out_path.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8061413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Computed and saved CEU MAF references (control + test)\n",
      " Saved: data/processed/hapmap/ceu_maf_reference.npz\n",
      "   chr2: mean control MAF = 0.18893962444832998\n",
      "   chr10: mean control MAF = 0.16131570012366628\n"
     ]
    }
   ],
   "source": [
    "def maf_from_G(G_sub):\n",
    "    M, N = G_sub.shape\n",
    "    maf = np.zeros(N, dtype=float)\n",
    "    for j in range(N):\n",
    "        col = G_sub[:, j]\n",
    "        mask = col >= 0\n",
    "        if mask.sum() == 0:\n",
    "            maf[j] = np.nan\n",
    "        else:\n",
    "            maf[j] = col[mask].mean() / 2.0\n",
    "    return maf\n",
    "\n",
    "maf_ctrl_chr2 = maf_from_G(G2[control_idx])\n",
    "maf_test_chr2 = maf_from_G(G2[test_idx])\n",
    "\n",
    "maf_ctrl_chr10 = maf_from_G(G10[control_idx])\n",
    "maf_test_chr10 = maf_from_G(G10[test_idx])\n",
    "\n",
    "freq_out = PROC_DIR / \"ceu_maf_reference.npz\"\n",
    "np.savez_compressed(\n",
    "    freq_out,\n",
    "    chr2_control_maf=maf_ctrl_chr2,\n",
    "    chr2_test_maf=maf_test_chr2,\n",
    "    chr2_snp_ids=rs2,\n",
    "    chr2_positions=pos2,\n",
    "    chr10_control_maf=maf_ctrl_chr10,\n",
    "    chr10_test_maf=maf_test_chr10,\n",
    "    chr10_snp_ids=rs10,\n",
    "    chr10_positions=pos10,\n",
    ")\n",
    "\n",
    "print(\" Computed and saved CEU MAF references (control + test)\")\n",
    "print(\" Saved:\", freq_out.relative_to(PROJECT_ROOT))\n",
    "print(\"   chr2: mean control MAF =\", float(np.nanmean(maf_ctrl_chr2)))\n",
    "print(\"   chr10: mean control MAF =\", float(np.nanmean(maf_ctrl_chr10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a3205ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Project root: /Users/erkmenerken/Desktop/430_project\n",
      " Raw phasing dir: /Users/erkmenerken/Desktop/430_project/data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED\n",
      " Regions: /Users/erkmenerken/Desktop/430_project/data/processed/hapmap/regions\n",
      " Cohorts: /Users/erkmenerken/Desktop/430_project/data/processed/hapmap/cohorts\n",
      " Output haplotypes: /Users/erkmenerken/Desktop/430_project/data/processed/hapmap/haplotypes\n",
      " Output blocks: /Users/erkmenerken/Desktop/430_project/data/processed/hapmap/blocks\n",
      "Exists - data/processed/hapmap/regions/CEU_chr2_5Mb.npz\n",
      "Exists - data/processed/hapmap/regions/CEU_chr10_1Mb.npz\n",
      "Exists - data/processed/hapmap/cohorts/ceu_control_test_split.json\n",
      "Exists - data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz\n",
      "Exists - data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def find_project_root(name=\"430_project\") -> Path:\n",
    "    cwd = Path.cwd()\n",
    "    if cwd.name == name:\n",
    "        return cwd\n",
    "    for p in [cwd] + list(cwd.parents):\n",
    "        if p.name == name:\n",
    "            return p\n",
    "    raise RuntimeError(f\"Could not find project root folder named '{name}' from {cwd}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(\"430_project\")\n",
    "\n",
    "RAW_HAPMAP = PROJECT_ROOT / \"data\" / \"raw\" / \"hapmap\"\n",
    "PHASE_DIR  = RAW_HAPMAP / \"phasing\" / \"HapMap3_r2\" / \"CEU\" / \"UNRELATED\"\n",
    "\n",
    "PROC_DIR      = PROJECT_ROOT / \"data\" / \"processed\" / \"hapmap\"\n",
    "REGION_DIR    = PROC_DIR / \"regions\"\n",
    "COHORT_DIR    = PROC_DIR / \"cohorts\"\n",
    "HAP_OUT_DIR   = PROC_DIR / \"haplotypes\"        # new\n",
    "BLOCK_OUT_DIR = PROC_DIR / \"blocks\"            # new (if not already)\n",
    "\n",
    "for d in [HAP_OUT_DIR, BLOCK_OUT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "REGION_CHR2  = REGION_DIR / \"CEU_chr2_5Mb.npz\"\n",
    "REGION_CHR10 = REGION_DIR / \"CEU_chr10_1Mb.npz\"\n",
    "COHORTS_JSON = COHORT_DIR / \"ceu_control_test_split.json\"\n",
    "\n",
    "PHASE_CHR2  = PHASE_DIR / \"hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz\"\n",
    "PHASE_CHR10 = PHASE_DIR / \"hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz\"\n",
    "\n",
    "print(\" Project root:\", PROJECT_ROOT)\n",
    "print(\" Raw phasing dir:\", PHASE_DIR)\n",
    "print(\" Regions:\", REGION_DIR)\n",
    "print(\" Cohorts:\", COHORT_DIR)\n",
    "print(\" Output haplotypes:\", HAP_OUT_DIR)\n",
    "print(\" Output blocks:\", BLOCK_OUT_DIR)\n",
    "\n",
    "for p in [REGION_CHR2, REGION_CHR10, COHORTS_JSON, PHASE_CHR2, PHASE_CHR10]:\n",
    "    print(\"Exists\" if p.exists() else \" Missing\", \"-\", p.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a3f2d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded regions:\n",
      "  chr2 : (174, 311) | SNPs: 311 | individuals: 174\n",
      "  chr10: (174, 610) | SNPs: 610 | individuals: 174\n",
      "\n",
      " Loaded CEU cohorts:\n",
      "  control n = 139\n",
      "  test    n = 35\n",
      "  case placeholder size = 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_region_npz(path: Path):\n",
    "    z = np.load(path, allow_pickle=True)\n",
    "    out = {k: z[k] for k in z.files}\n",
    "    # make sure types are friendly\n",
    "    out[\"snp_ids\"] = out[\"snp_ids\"].astype(object)\n",
    "    out[\"sample_ids\"] = out[\"sample_ids\"].astype(object)\n",
    "    out[\"minor_alleles\"] = out[\"minor_alleles\"].astype(object)\n",
    "    out[\"major_alleles\"] = out[\"major_alleles\"].astype(object)\n",
    "    return out\n",
    "\n",
    "r2 = load_region_npz(REGION_CHR2)\n",
    "r10 = load_region_npz(REGION_CHR10)\n",
    "\n",
    "with open(COHORTS_JSON, \"r\") as f:\n",
    "    cohorts = json.load(f)\n",
    "\n",
    "print(\" Loaded regions:\")\n",
    "print(\"  chr2 :\", r2[\"G\"].shape, \"| SNPs:\", len(r2[\"snp_ids\"]), \"| individuals:\", len(r2[\"sample_ids\"]))\n",
    "print(\"  chr10:\", r10[\"G\"].shape, \"| SNPs:\", len(r10[\"snp_ids\"]), \"| individuals:\", len(r10[\"sample_ids\"]))\n",
    "\n",
    "control_idx = np.array(cohorts[\"control\"][\"indices_in_ceu_matrix\"], dtype=int)\n",
    "test_idx    = np.array(cohorts[\"test\"][\"indices_in_ceu_matrix\"], dtype=int)\n",
    "\n",
    "print(\"\\n Loaded CEU cohorts:\")\n",
    "print(\"  control n =\", len(control_idx))\n",
    "print(\"  test    n =\", len(test_idx))\n",
    "print(\"  case placeholder size =\", len(cohorts[\"case\"][\"sample_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d433896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Building blocks for chr2 (phased-compatible SNP subset)\n",
      " chr2 phased-compatible SNPs: 118\n",
      " chr2 inferred blocks: 3\n",
      " Saved blocks â†’ data/processed/hapmap/blocks/CEU_chr2_5Mb.blocks.phased_compatible.json\n",
      " Blocks saved for CEU_chr2_5Mb: 3 blocks\n",
      "\n",
      "\n",
      " Building blocks for chr10 (phased-compatible SNP subset)\n",
      " chr10 phased-compatible SNPs: 129\n",
      " chr10 inferred blocks: 2\n",
      " Saved blocks â†’ data/processed/hapmap/blocks/CEU_chr10_1Mb.blocks.phased_compatible.json\n",
      " Blocks saved for CEU_chr10_1Mb: 2 blocks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def adjacent_r2_from_G(G):\n",
    "    \"\"\"\n",
    "    Compute r^2 between adjacent SNPs using correlation on dosage {0,1,2},\n",
    "    ignoring missing=-1. Returns length (N-1) array.\n",
    "    \"\"\"\n",
    "    X = G.astype(float)\n",
    "    M, N = X.shape\n",
    "    out = np.zeros(N - 1, dtype=float)\n",
    "\n",
    "    for j in range(N - 1):\n",
    "        x = X[:, j]\n",
    "        y = X[:, j + 1]\n",
    "        mask = (x >= 0) & (y >= 0)\n",
    "        if mask.sum() < 10:\n",
    "            out[j] = 0.0\n",
    "            continue\n",
    "\n",
    "        xv = x[mask] - x[mask].mean()\n",
    "        yv = y[mask] - y[mask].mean()\n",
    "        denom = np.sqrt((xv * xv).sum() * (yv * yv).sum())\n",
    "        if denom == 0:\n",
    "            out[j] = 0.0\n",
    "            continue\n",
    "\n",
    "        r = float((xv * yv).sum() / denom)\n",
    "        out[j] = r * r\n",
    "    return out\n",
    "\n",
    "def build_blocks_from_adjacent_r2(r2, threshold=0.8, min_snps=5, max_snps=80):\n",
    "    \"\"\"\n",
    "    Create blocks by cutting when adjacent r^2 < threshold.\n",
    "    Then:\n",
    "      - merge blocks smaller than min_snps into previous\n",
    "      - split blocks larger than max_snps\n",
    "    Returns list of (start_idx, end_idx) inclusive, in SNP-index space.\n",
    "    \"\"\"\n",
    "    N = len(r2) + 1\n",
    "    cuts = [0]\n",
    "    for j, v in enumerate(r2):\n",
    "        if v < threshold:\n",
    "            cuts.append(j + 1)\n",
    "    cuts.append(N)\n",
    "\n",
    "    blocks = [(cuts[i], cuts[i + 1] - 1) for i in range(len(cuts) - 1)]\n",
    "\n",
    "    # merge tiny blocks into previous\n",
    "    merged = []\n",
    "    for s, e in blocks:\n",
    "        if not merged:\n",
    "            merged.append((s, e))\n",
    "        else:\n",
    "            if (e - s + 1) < min_snps:\n",
    "                ps, pe = merged[-1]\n",
    "                merged[-1] = (ps, e)\n",
    "            else:\n",
    "                merged.append((s, e))\n",
    "\n",
    "    # split huge blocks\n",
    "    final = []\n",
    "    for s, e in merged:\n",
    "        while (e - s + 1) > max_snps:\n",
    "            final.append((s, s + max_snps - 1))\n",
    "            s = s + max_snps\n",
    "        final.append((s, e))\n",
    "\n",
    "    return final\n",
    "\n",
    "def save_blocks_json_phased_compatible(region_name, pc, blocks, params):\n",
    "    \"\"\"\n",
    "    Saves blocks JSON using the phased-compatible SNP list (pc['snp_ids_sub'], pc['positions_sub']).\n",
    "    \"\"\"\n",
    "    out = BLOCK_OUT_DIR / f\"{region_name}.blocks.phased_compatible.json\"\n",
    "\n",
    "    snp_ids = pc[\"snp_ids_sub\"]\n",
    "    positions = pc[\"positions_sub\"]\n",
    "\n",
    "    payload = {\n",
    "        \"region_name\": region_name,\n",
    "        \"phased_compatible\": True,\n",
    "        \"block_params\": params,\n",
    "        \"num_snps\": int(len(snp_ids)),\n",
    "        \"num_blocks\": int(len(blocks)),\n",
    "        \"blocks\": [\n",
    "            {\n",
    "                \"block_id\": int(i),\n",
    "                \"start_snp_index\": int(s),\n",
    "                \"end_snp_index\": int(e),\n",
    "                \"num_snps\": int(e - s + 1),\n",
    "                \"start_pos\": int(positions[s]),\n",
    "                \"end_pos\": int(positions[e]),\n",
    "                \"snp_ids\": [str(x) for x in snp_ids[s:e+1]],\n",
    "            }\n",
    "            for i, (s, e) in enumerate(blocks)\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    out.write_text(json.dumps(payload, indent=2))\n",
    "    print(f\" Saved blocks â†’ {out.relative_to(PROJECT_ROOT)}\")\n",
    "    print(f\" Blocks saved for {region_name}: {len(blocks)} blocks\\n\")\n",
    "    return out\n",
    "\n",
    "\n",
    "BLOCK_PARAMS = {\"threshold\": 0.8, \"min_snps\": 5, \"max_snps\": 80}\n",
    "\n",
    "# --- chr2 (PHASED-COMPATIBLE) ---\n",
    "print(\"\\n Building blocks for chr2 (phased-compatible SNP subset)\")\n",
    "pc2_adj = adjacent_r2_from_G(pc2[\"G_sub\"])\n",
    "blocks_chr2 = build_blocks_from_adjacent_r2(pc2_adj, **BLOCK_PARAMS)\n",
    "print(f\" chr2 phased-compatible SNPs: {pc2['G_sub'].shape[1]}\")\n",
    "print(f\" chr2 inferred blocks: {len(blocks_chr2)}\")\n",
    "blocks_chr2_path = save_blocks_json_phased_compatible(\"CEU_chr2_5Mb\", pc2, blocks_chr2, BLOCK_PARAMS)\n",
    "\n",
    "# --- chr10 (PHASED-COMPATIBLE) ---\n",
    "print(\"\\n Building blocks for chr10 (phased-compatible SNP subset)\")\n",
    "pc10_adj = adjacent_r2_from_G(pc10[\"G_sub\"])\n",
    "blocks_chr10 = build_blocks_from_adjacent_r2(pc10_adj, **BLOCK_PARAMS)\n",
    "print(f\" chr10 phased-compatible SNPs: {pc10['G_sub'].shape[1]}\")\n",
    "print(f\" chr10 inferred blocks: {len(blocks_chr10)}\")\n",
    "blocks_chr10_path = save_blocks_json_phased_compatible(\"CEU_chr10_1Mb\", pc10, blocks_chr10, BLOCK_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1466136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading phased file: hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz\n",
      " Phased rows loaded: 116430 | columns: 36\n",
      "\n",
      " Loading phased file: hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz\n",
      " Phased rows loaded: 73832 | columns: 36\n",
      "\n",
      "ðŸ”— [chr2] Individuals:\n",
      "  phased individuals total: 17\n",
      "  phased âˆ© region:          17\n",
      "\n",
      "ðŸ”— [chr2] SNPs:\n",
      "  region SNPs: 311\n",
      "  matched in phased: 118\n",
      " [chr2] Subset region G to phased-compatible shape: (17, 118)\n",
      " [chr2] Phased allele matrices:\n",
      "   A: (118, 17) | B: (118, 17)\n",
      " [chr2] Confirm SNP order alignment: 118 rows\n",
      " [chr2] Positions match between phased and region-subset.\n",
      "\n",
      "ðŸ”— [chr10] Individuals:\n",
      "  phased individuals total: 17\n",
      "  phased âˆ© region:          17\n",
      "\n",
      "ðŸ”— [chr10] SNPs:\n",
      "  region SNPs: 610\n",
      "  matched in phased: 129\n",
      " [chr10] Subset region G to phased-compatible shape: (17, 129)\n",
      " [chr10] Phased allele matrices:\n",
      "   A: (129, 17) | B: (129, 17)\n",
      " [chr10] Confirm SNP order alignment: 129 rows\n",
      " [chr10] Positions match between phased and region-subset.\n",
      "\n",
      " Done. You now have phased-compatible region subsets:\n",
      "  chr2: G_sub (17, 118) | phased indiv: 17 | SNPs: 118\n",
      "  chr10: G_sub (17, 129) | phased indiv: 17 | SNPs: 129\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_phased_df(phase_gz_path):\n",
    "    print(f\"\\n Loading phased file: {phase_gz_path.name}\")\n",
    "    df = pd.read_csv(\n",
    "        phase_gz_path,\n",
    "        sep=r\"\\s+\",\n",
    "        engine=\"python\",\n",
    "        compression=\"gzip\",\n",
    "        dtype=str,\n",
    "    )\n",
    "    print(f\" Phased rows loaded: {len(df)} | columns: {len(df.columns)}\")\n",
    "    if \"rsID\" not in df.columns or \"position_b36\" not in df.columns:\n",
    "        raise ValueError(\"Unexpected phased file columns. Expected rsID and position_b36.\")\n",
    "    return df\n",
    "\n",
    "def phased_individuals_from_columns(df):\n",
    "    hap_cols = [c for c in df.columns if c.endswith(\"_A\") or c.endswith(\"_B\")]\n",
    "    if len(hap_cols) == 0:\n",
    "        raise ValueError(\"No _A/_B haplotype columns found in phased file.\")\n",
    "    individuals = sorted(set(c[:-2] for c in hap_cols))  # strip _A/_B\n",
    "    # keep only those that have both columns\n",
    "    individuals = [i for i in individuals if f\"{i}_A\" in df.columns and f\"{i}_B\" in df.columns]\n",
    "    return individuals\n",
    "\n",
    "def make_phased_compatible_region(region, phased_df, region_name):\n",
    "    \"\"\"\n",
    "    region: dict loaded from your region npz (r2 or r10)\n",
    "    phased_df: full phased dataframe for that chromosome\n",
    "    Returns a dict with phased-compatible data:\n",
    "      - G_sub (individuals x snps)\n",
    "      - sample_ids_sub\n",
    "      - snp_ids_sub\n",
    "      - positions_sub\n",
    "      - phased alleles A/B matrices (snps x individuals)\n",
    "      - individuals list (phased)\n",
    "      - idx maps\n",
    "    \"\"\"\n",
    "    region_sample_ids = np.array([str(x) for x in region[\"sample_ids\"]], dtype=object)\n",
    "    region_snp_ids    = np.array([str(x) for x in region[\"snp_ids\"]], dtype=object)\n",
    "    region_positions  = np.array(region[\"positions\"], dtype=int)\n",
    "\n",
    "    # Individuals available in phased\n",
    "    phased_indivs_all = phased_individuals_from_columns(phased_df)\n",
    "    region_indiv_set = set(region_sample_ids.tolist())\n",
    "    phased_indivs = [i for i in phased_indivs_all if i in region_indiv_set]\n",
    "\n",
    "    print(f\"\\n [{region_name}] Individuals:\")\n",
    "    print(f\"  phased individuals total: {len(phased_indivs_all)}\")\n",
    "    print(f\"  phased âˆ© region:          {len(phased_indivs)}\")\n",
    "\n",
    "    if len(phased_indivs) == 0:\n",
    "        raise RuntimeError(f\"[{region_name}] No overlapping individuals between region and phased file.\")\n",
    "\n",
    "    # SNP intersection by rsID\n",
    "    phased_rsids_set = set(phased_df[\"rsID\"].astype(str).tolist())\n",
    "    keep_snp_mask = np.array([rs in phased_rsids_set for rs in region_snp_ids], dtype=bool)\n",
    "    snp_ids_sub = region_snp_ids[keep_snp_mask]\n",
    "    positions_sub = region_positions[keep_snp_mask]\n",
    "\n",
    "    print(f\"\\n [{region_name}] SNPs:\")\n",
    "    print(f\"  region SNPs: {len(region_snp_ids)}\")\n",
    "    print(f\"  matched in phased: {len(snp_ids_sub)}\")\n",
    "\n",
    "    if len(snp_ids_sub) == 0:\n",
    "        raise RuntimeError(f\"[{region_name}] No SNPs from region found in phased file.\")\n",
    "\n",
    "    # Subset region genotype matrix to phased-compatible individuals + SNPs\n",
    "    indiv_idx_in_region = np.array([np.where(region_sample_ids == i)[0][0] for i in phased_indivs], dtype=int)\n",
    "    snp_idx_in_region = np.where(keep_snp_mask)[0]\n",
    "\n",
    "    G_sub = region[\"G\"][indiv_idx_in_region][:, snp_idx_in_region]   # (n_indiv, n_snps)\n",
    "    sample_ids_sub = region_sample_ids[indiv_idx_in_region]\n",
    "\n",
    "    print(f\" [{region_name}] Subset region G to phased-compatible shape: {G_sub.shape}\")\n",
    "\n",
    "    # Now subset phased dataframe rows to our SNP list, and reorder to match region order\n",
    "    phased_sub = phased_df[phased_df[\"rsID\"].isin(set(snp_ids_sub.tolist()))].copy()\n",
    "    # reorder rows to match snp_ids_sub order\n",
    "    order_map = {rsid: i for i, rsid in enumerate(snp_ids_sub.tolist())}\n",
    "    phased_sub[\"__order\"] = phased_sub[\"rsID\"].map(order_map)\n",
    "    phased_sub = phased_sub.sort_values(\"__order\").drop(columns=\"__order\")\n",
    "\n",
    "    # Columns for A/B\n",
    "    A_cols = [f\"{i}_A\" for i in phased_indivs]\n",
    "    B_cols = [f\"{i}_B\" for i in phased_indivs]\n",
    "\n",
    "    alleles_A = phased_sub[A_cols].to_numpy(dtype=object)  # (n_snps, n_indiv)\n",
    "    alleles_B = phased_sub[B_cols].to_numpy(dtype=object)\n",
    "\n",
    "    # sanity prints\n",
    "    print(f\" [{region_name}] Phased allele matrices:\")\n",
    "    print(f\"   A: {alleles_A.shape} | B: {alleles_B.shape}\")\n",
    "    print(f\" [{region_name}] Confirm SNP order alignment: {len(phased_sub)} rows\")\n",
    "\n",
    "    # best-effort position check\n",
    "    phased_pos = phased_sub[\"position_b36\"].astype(int).to_numpy()\n",
    "    if len(phased_pos) == len(positions_sub) and np.all(phased_pos == positions_sub):\n",
    "        print(f\" [{region_name}] Positions match between phased and region-subset.\")\n",
    "    else:\n",
    "        print(f\" [{region_name}] Position mismatch (rsID alignment is still OK).\")\n",
    "        print(\"   first 5 phased positions:\", phased_pos[:5])\n",
    "        print(\"   first 5 region positions:\", positions_sub[:5])\n",
    "\n",
    "    return {\n",
    "        \"region_name\": region_name,\n",
    "        \"G_sub\": G_sub,\n",
    "        \"sample_ids_sub\": sample_ids_sub,\n",
    "        \"snp_ids_sub\": snp_ids_sub,\n",
    "        \"positions_sub\": positions_sub,\n",
    "        \"alleles_A\": alleles_A,\n",
    "        \"alleles_B\": alleles_B,\n",
    "        \"phased_individuals\": phased_indivs,\n",
    "        \"indiv_idx_in_region\": indiv_idx_in_region,\n",
    "        \"snp_idx_in_region\": snp_idx_in_region,\n",
    "    }\n",
    "\n",
    "# Load phased dataframes\n",
    "df_phase_chr2 = load_phased_df(PHASE_CHR2)\n",
    "df_phase_chr10 = load_phased_df(PHASE_CHR10)\n",
    "\n",
    "# Build phased-compatible subsets\n",
    "pc2 = make_phased_compatible_region(r2, df_phase_chr2, \"chr2\")\n",
    "pc10 = make_phased_compatible_region(r10, df_phase_chr10, \"chr10\")\n",
    "\n",
    "print(\"\\n Done. You now have phased-compatible region subsets:\")\n",
    "print(\"  chr2: G_sub\", pc2[\"G_sub\"].shape, \"| phased indiv:\", len(pc2[\"phased_individuals\"]), \"| SNPs:\", len(pc2[\"snp_ids_sub\"]))\n",
    "print(\"  chr10: G_sub\", pc10[\"G_sub\"].shape, \"| phased indiv:\", len(pc10[\"phased_individuals\"]), \"| SNPs:\", len(pc10[\"snp_ids_sub\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e40fd4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Building haplotype histograms for CEU_chr2_5Mb (PHASED-COMPATIBLE subset)\n",
      " Total phased-compatible individuals: 17\n",
      " Control individuals available in phased subset: 16\n",
      "   block 0: SNPs 0-79 | unique=31 | top1=2\n",
      "\n",
      " Saved haplotype histograms â†’ data/processed/hapmap/haplotypes/CEU_chr2_5Mb.control_haplotypes.phased_compatible.json\n",
      "\n",
      " Building haplotype histograms for CEU_chr10_1Mb (PHASED-COMPATIBLE subset)\n",
      " Total phased-compatible individuals: 17\n",
      " Control individuals available in phased subset: 16\n",
      "   block 0: SNPs 0-79 | unique=13 | top1=9\n",
      "\n",
      " Saved haplotype histograms â†’ data/processed/hapmap/haplotypes/CEU_chr10_1Mb.control_haplotypes.phased_compatible.json\n",
      "\n",
      " Done building phased-compatible control haplotype histograms.\n",
      "chr2 â†’ data/processed/hapmap/haplotypes/CEU_chr2_5Mb.control_haplotypes.phased_compatible.json\n",
      "chr10 â†’ data/processed/hapmap/haplotypes/CEU_chr10_1Mb.control_haplotypes.phased_compatible.json\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def hap_strings_for_block(allele_matrix, start, end):\n",
    "    \"\"\"\n",
    "    allele_matrix: (N_snps, N_individuals), single-letter alleles (strings)\n",
    "    returns list length N_individuals where each is a haplotype string for [start:end]\n",
    "    \"\"\"\n",
    "    block = allele_matrix[start:end+1, :]  # (block_len, n_ind)\n",
    "    return [\"\".join(block[:, j].tolist()) for j in range(block.shape[1])]\n",
    "\n",
    "def build_haplotype_histograms_from_pc(region_name, blocks, pc, cohorts, top_k=50):\n",
    "    \"\"\"\n",
    "    pc is the phased-compatible dict from Cell 4:\n",
    "      pc[\"alleles_A\"], pc[\"alleles_B\"] : (n_snps, n_indiv)\n",
    "      pc[\"sample_ids_sub\"] : region sample IDs for the phased subset (length n_indiv)\n",
    "      pc[\"snp_ids_sub\"], pc[\"positions_sub\"]\n",
    "    cohorts is your ceu_control_test_split.json already loaded.\n",
    "\n",
    "    We count haplotypes ONLY over CONTROL individuals, but restricted to those\n",
    "    that exist in the phased subset.\n",
    "    \"\"\"\n",
    "    print(f\"\\n Building haplotype histograms for {region_name} (PHASED-COMPATIBLE subset)\")\n",
    "\n",
    "    # These are the phased-subset individual IDs (in the same order as columns in alleles_A/B)\n",
    "    phased_region_ids = [str(x) for x in pc[\"sample_ids_sub\"]]\n",
    "\n",
    "    # Control individuals in the FULL CEU region (174 people)\n",
    "    control_ids_full = set(str(x) for x in cohorts[\"control\"][\"sample_ids\"])\n",
    "\n",
    "    # Determine which phased-subset columns are in control\n",
    "    control_cols = [j for j, sid in enumerate(phased_region_ids) if sid in control_ids_full]\n",
    "\n",
    "    print(f\" Total phased-compatible individuals: {len(phased_region_ids)}\")\n",
    "    print(f\" Control individuals available in phased subset: {len(control_cols)}\")\n",
    "    if len(control_cols) == 0:\n",
    "        raise RuntimeError(\n",
    "            f\"No CONTROL individuals overlap with phased subset for {region_name}. \"\n",
    "            \"This can happen if your control split contains mostly people not in the UNRELATED phased set.\"\n",
    "        )\n",
    "\n",
    "    alleles_A = pc[\"alleles_A\"]\n",
    "    alleles_B = pc[\"alleles_B\"]\n",
    "\n",
    "    block_payload = []\n",
    "    for block_id, (s, e) in enumerate(blocks):\n",
    "        hA_all = hap_strings_for_block(alleles_A, s, e)\n",
    "        hB_all = hap_strings_for_block(alleles_B, s, e)\n",
    "\n",
    "        ctr = Counter()\n",
    "        for col in control_cols:\n",
    "            ctr[hA_all[col]] += 1\n",
    "            ctr[hB_all[col]] += 1\n",
    "\n",
    "        total = int(sum(ctr.values()))\n",
    "        top = ctr.most_common(top_k)\n",
    "        top_haps = [h for h, _ in top]\n",
    "        top_counts = [int(c) for _, c in top]\n",
    "        other_count = int(total - sum(top_counts))\n",
    "\n",
    "        block_payload.append({\n",
    "            \"block_id\": int(block_id),\n",
    "            \"start_snp_index\": int(s),\n",
    "            \"end_snp_index\": int(e),\n",
    "            \"num_snps\": int(e - s + 1),\n",
    "            \"total_haplotypes_counted\": total,  # should be 2 * (#control_cols)\n",
    "            \"top_k\": int(top_k),\n",
    "            \"top_haplotypes\": top_haps,\n",
    "            \"top_counts\": top_counts,\n",
    "            \"other_count\": other_count,\n",
    "        })\n",
    "\n",
    "        if block_id % 10 == 0:\n",
    "            top1 = top_counts[0] if top_counts else 0\n",
    "            print(f\"   block {block_id}: SNPs {s}-{e} | unique={len(ctr)} | top1={top1}\")\n",
    "\n",
    "    out = HAP_OUT_DIR / f\"{region_name}.control_haplotypes.phased_compatible.json\"\n",
    "    out.write_text(json.dumps({\n",
    "        \"region_name\": region_name,\n",
    "        \"note\": (\n",
    "            \"This file is built on the intersection of (region SNPs âˆ© phased SNPs) and \"\n",
    "            \"(region individuals âˆ© phased UNRELATED CEU individuals).\"\n",
    "        ),\n",
    "        \"counts_from\": \"CONTROL cohort only, restricted to phased-compatible individuals\",\n",
    "        \"phased_compatible\": {\n",
    "            \"num_individuals_total\": int(len(phased_region_ids)),\n",
    "            \"num_control_individuals_used\": int(len(control_cols)),\n",
    "            \"num_snps_total\": int(len(pc[\"snp_ids_sub\"])),\n",
    "        },\n",
    "        \"blocks\": block_payload\n",
    "    }, indent=2))\n",
    "\n",
    "    print(f\"\\n Saved haplotype histograms â†’ {out.relative_to(PROJECT_ROOT)}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def assert_blocks_fit_pc(blocks, pc, region_name):\n",
    "    n_snps = len(pc[\"snp_ids_sub\"])\n",
    "    max_end = max(e for s, e in blocks)\n",
    "    if max_end >= n_snps:\n",
    "        raise RuntimeError(\n",
    "            f\"Blocks for {region_name} do not fit phased-compatible SNP count. \"\n",
    "            f\"max_end={max_end}, but phased-compatible n_snps={n_snps}. \"\n",
    "            \"Rebuild blocks using pc['G_sub'].\"\n",
    "        )\n",
    "\n",
    "# Ensure blocks fit phased-compatible SNP counts\n",
    "assert_blocks_fit_pc(blocks_chr2, pc2, \"chr2\")\n",
    "assert_blocks_fit_pc(blocks_chr10, pc10, \"chr10\")\n",
    "\n",
    "# Build histograms\n",
    "hap_chr2_out = build_haplotype_histograms_from_pc(\"CEU_chr2_5Mb\", blocks_chr2, pc2, cohorts, top_k=50)\n",
    "hap_chr10_out = build_haplotype_histograms_from_pc(\"CEU_chr10_1Mb\", blocks_chr10, pc10, cohorts, top_k=50)\n",
    "\n",
    "print(\"\\n Done building phased-compatible control haplotype histograms.\")\n",
    "print(\"chr2 â†’\", hap_chr2_out.relative_to(PROJECT_ROOT))\n",
    "print(\"chr10 â†’\", hap_chr10_out.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "296185c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SUMMARY OF WHAT WE NOW HAVE\n",
      "\n",
      "Raw downloads (existing):\n",
      " - data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr2_ceu.unr.phased.gz\n",
      " - data/raw/hapmap/phasing/HapMap3_r2/CEU/UNRELATED/hapmap3_r2_b36_fwd.consensus.qc.poly.chr10_ceu.unr.phased.gz\n",
      "\n",
      "Processed regions (existing):\n",
      " - data/processed/hapmap/regions/CEU_chr2_5Mb.npz\n",
      " - data/processed/hapmap/regions/CEU_chr10_1Mb.npz\n",
      "\n",
      "New outputs created now:\n",
      " - Blocks chr2: data/processed/hapmap/blocks/CEU_chr2_5Mb.blocks.phased_compatible.json\n",
      " - Blocks chr10: data/processed/hapmap/blocks/CEU_chr10_1Mb.blocks.phased_compatible.json\n",
      " - Hap hist chr2: data/processed/hapmap/haplotypes/CEU_chr2_5Mb.control_haplotypes.phased_compatible.json\n",
      " - Hap hist chr10: data/processed/hapmap/haplotypes/CEU_chr10_1Mb.control_haplotypes.phased_compatible.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n SUMMARY OF WHAT WE NOW HAVE\")\n",
    "\n",
    "print(\"\\nRaw downloads (existing):\")\n",
    "print(\" -\", (PHASE_CHR2).relative_to(PROJECT_ROOT))\n",
    "print(\" -\", (PHASE_CHR10).relative_to(PROJECT_ROOT))\n",
    "\n",
    "print(\"\\nProcessed regions (existing):\")\n",
    "print(\" -\", (REGION_CHR2).relative_to(PROJECT_ROOT))\n",
    "print(\" -\", (REGION_CHR10).relative_to(PROJECT_ROOT))\n",
    "\n",
    "print(\"\\nNew outputs created now:\")\n",
    "print(\" - Blocks chr2:\", blocks_chr2_path.relative_to(PROJECT_ROOT))\n",
    "print(\" - Blocks chr10:\", blocks_chr10_path.relative_to(PROJECT_ROOT))\n",
    "print(\" - Hap hist chr2:\", hap_chr2_out.relative_to(PROJECT_ROOT))\n",
    "print(\" - Hap hist chr10:\", hap_chr10_out.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f3b43f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr2: phased-compatible SNPs=118, individuals=17\n",
      "   sample_ids_sub=17, snp_ids_sub=118\n",
      "chr10: phased-compatible SNPs=129, individuals=17\n",
      "   sample_ids_sub=17, snp_ids_sub=129\n",
      "\n",
      " Haplotypes output dir: data/processed/hapmap/haplotypes\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "HAP_OUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"hapmap\" / \"haplotypes\"\n",
    "HAP_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "required_vars = [\"pc2\", \"pc10\", \"blocks_chr2\", \"blocks_chr10\", \"cohorts\", \"PROJECT_ROOT\"]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing variables from earlier cells: {missing}\")\n",
    "\n",
    "def _check_pc(pc, name):\n",
    "    A = pc[\"alleles_A\"]; B = pc[\"alleles_B\"]\n",
    "    assert A.shape == B.shape, f\"{name}: A/B shape mismatch\"\n",
    "    n_snps, n_ind = A.shape\n",
    "    print(f\"{name}: phased-compatible SNPs={n_snps}, individuals={n_ind}\")\n",
    "    print(f\"   sample_ids_sub={len(pc['sample_ids_sub'])}, snp_ids_sub={len(pc['snp_ids_sub'])}\")\n",
    "    # Blocks must fit SNP count\n",
    "    max_end = max(e for s, e in (blocks_chr2 if name=='chr2' else blocks_chr10))\n",
    "    if max_end >= n_snps:\n",
    "        raise RuntimeError(f\"{name}: blocks don't fit SNP count (max_end={max_end}, n_snps={n_snps}). Rebuild Cell 3 on pc['G_sub'].\")\n",
    "\n",
    "_check_pc(pc2, \"chr2\")\n",
    "_check_pc(pc10, \"chr10\")\n",
    "\n",
    "print(\"\\n Haplotypes output dir:\", HAP_OUT_DIR.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "135a2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "def hap_strings_for_block(allele_matrix, start, end):\n",
    "    \"\"\"\n",
    "    allele_matrix: (N_snps, N_individuals) of single-letter alleles (strings)\n",
    "    returns list length N_individuals where each element is the haplotype string over SNPs [start:end]\n",
    "    \"\"\"\n",
    "    block = allele_matrix[start:end+1, :]  \n",
    "    return [\"\".join(block[:, j].tolist()) for j in range(block.shape[1])]\n",
    "\n",
    "def compute_control_cols_in_pc(pc, cohorts):\n",
    "    \"\"\"\n",
    "    pc has sample_ids_sub = individuals in phased-compatible subset (same order as allele columns).\n",
    "    cohorts['control']['sample_ids'] are the control IDs from full CEU (unphased split).\n",
    "    Return list of column indices in pc corresponding to CONTROL individuals.\n",
    "    \"\"\"\n",
    "    pc_ids = [str(x) for x in pc[\"sample_ids_sub\"]]\n",
    "    control_set = set(str(x) for x in cohorts[\"control\"][\"sample_ids\"])\n",
    "    control_cols = [j for j, sid in enumerate(pc_ids) if sid in control_set]\n",
    "    return control_cols\n",
    "\n",
    "def save_control_haplotype_histograms(region_name, pc, blocks, cohorts, top_k=50):\n",
    "    \"\"\"\n",
    "    Writes:\n",
    "      data/processed/hapmap/haplotypes/{region_name}.control_haplotypes.phased_compatible.json\n",
    "\n",
    "    Counts are over haplotypes => 2 per person (A and B haplotypes).\n",
    "    Uses CONTROL only (public reference), restricted to phased-compatible individuals.\n",
    "    \"\"\"\n",
    "    A = pc[\"alleles_A\"]\n",
    "    B = pc[\"alleles_B\"]\n",
    "    snp_ids = [str(x) for x in pc[\"snp_ids_sub\"]]\n",
    "    positions = [int(x) for x in pc[\"positions_sub\"]]\n",
    "    pc_ids = [str(x) for x in pc[\"sample_ids_sub\"]]\n",
    "\n",
    "    control_cols = compute_control_cols_in_pc(pc, cohorts)\n",
    "    if len(control_cols) == 0:\n",
    "        raise RuntimeError(\n",
    "            f\"{region_name}: No CONTROL individuals overlap with phased-compatible subset. \"\n",
    "            \"This can happen depending on your split + UNRELATED set.\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n [{region_name}] CONTROL haplotype histograms (phased-compatible)\")\n",
    "    print(f\" phased-compatible individuals total: {len(pc_ids)}\")\n",
    "    print(f\" control individuals used: {len(control_cols)} (=> {2*len(control_cols)} haplotypes)\")\n",
    "    print(f\" SNPs used: {A.shape[0]}\")\n",
    "\n",
    "    block_payload = []\n",
    "    for block_id, (s, e) in enumerate(blocks):\n",
    "\n",
    "        hA_all = hap_strings_for_block(A, s, e)\n",
    "        hB_all = hap_strings_for_block(B, s, e)\n",
    "\n",
    "        ctr = Counter()\n",
    "        for col in control_cols:\n",
    "            ctr[hA_all[col]] += 1\n",
    "            ctr[hB_all[col]] += 1\n",
    "\n",
    "        total = int(sum(ctr.values()))\n",
    "        top = ctr.most_common(top_k)\n",
    "        top_haps = [h for h, _ in top]\n",
    "        top_counts = [int(c) for _, c in top]\n",
    "        other_count = int(total - sum(top_counts))\n",
    "\n",
    "        block_payload.append({\n",
    "            \"block_id\": int(block_id),\n",
    "            \"start_snp_index\": int(s),\n",
    "            \"end_snp_index\": int(e),\n",
    "            \"num_snps\": int(e - s + 1),\n",
    "            \"start_pos\": int(positions[s]),\n",
    "            \"end_pos\": int(positions[e]),\n",
    "            \"total_haplotypes_counted\": total,  \n",
    "            \"top_k\": int(top_k),\n",
    "            \"top_haplotypes\": top_haps,\n",
    "            \"top_counts\": top_counts,\n",
    "            \"other_count\": other_count,\n",
    "        })\n",
    "\n",
    "        if block_id % 10 == 0:\n",
    "            print(f\"   block {block_id}: SNPs {s}-{e} | unique={len(ctr)} | top1={top_counts[0] if top_counts else 0}\")\n",
    "\n",
    "    out_path = HAP_OUT_DIR / f\"{region_name}.control_haplotypes.phased_compatible.json\"\n",
    "    payload = {\n",
    "        \"region_name\": region_name,\n",
    "        \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"source\": \"HapMap3 r2 phased (CEU UNRELATED) + CEU control split from unphased genotypes\",\n",
    "        \"counts_from\": \"CONTROL cohort only (public reference), restricted to phased-compatible subset\",\n",
    "        \"phased_compatible\": {\n",
    "            \"num_snps\": int(A.shape[0]),\n",
    "            \"num_individuals_total\": int(A.shape[1]),\n",
    "            \"num_control_individuals_used\": int(len(control_cols)),\n",
    "        },\n",
    "        \"note\": \"Counts are over haplotypes (2 per person: A and B).\",\n",
    "        \"blocks\": block_payload,\n",
    "    }\n",
    "    out_path.write_text(json.dumps(payload, indent=2))\n",
    "    print(f\"\\n Saved â†’ {out_path.relative_to(PROJECT_ROOT)}\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f802b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [CEU_chr2_5Mb] CONTROL haplotype histograms (phased-compatible)\n",
      " phased-compatible individuals total: 17\n",
      " control individuals used: 16 (=> 32 haplotypes)\n",
      " SNPs used: 118\n",
      "   block 0: SNPs 0-79 | unique=31 | top1=2\n",
      "\n",
      " Saved â†’ data/processed/hapmap/haplotypes/CEU_chr2_5Mb.control_haplotypes.phased_compatible.json\n",
      "\n",
      " [CEU_chr10_1Mb] CONTROL haplotype histograms (phased-compatible)\n",
      " phased-compatible individuals total: 17\n",
      " control individuals used: 16 (=> 32 haplotypes)\n",
      " SNPs used: 129\n",
      "   block 0: SNPs 0-79 | unique=13 | top1=9\n",
      "\n",
      " Saved â†’ data/processed/hapmap/haplotypes/CEU_chr10_1Mb.control_haplotypes.phased_compatible.json\n",
      "\n",
      " Preprocessing milestone complete for Method 2.\n",
      "chr2: data/processed/hapmap/haplotypes/CEU_chr2_5Mb.control_haplotypes.phased_compatible.json\n",
      "chr10: data/processed/hapmap/haplotypes/CEU_chr10_1Mb.control_haplotypes.phased_compatible.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hap_chr2_out = save_control_haplotype_histograms(\n",
    "    region_name=\"CEU_chr2_5Mb\",\n",
    "    pc=pc2,\n",
    "    blocks=blocks_chr2,\n",
    "    cohorts=cohorts,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "hap_chr10_out = save_control_haplotype_histograms(\n",
    "    region_name=\"CEU_chr10_1Mb\",\n",
    "    pc=pc10,\n",
    "    blocks=blocks_chr10,\n",
    "    cohorts=cohorts,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "print(\"\\n Preprocessing milestone complete for Method 2.\")\n",
    "print(\"chr2:\", hap_chr2_out.relative_to(PROJECT_ROOT))\n",
    "print(\"chr10:\", hap_chr10_out.relative_to(PROJECT_ROOT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
