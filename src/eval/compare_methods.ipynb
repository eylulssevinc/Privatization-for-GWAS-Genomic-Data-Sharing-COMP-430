{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compare Methods (1/2/3)\n",
        "\n",
        "This notebook compares privacy, utility, and distortion across Method 1 (SNP Laplace DP), Method 2 (Haploblock DP), and Method 3 (GRR LDP) for chr2_5Mb and chr10_1Mb using a common epsilon grid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ROOT = /Users/erkmenerken/Desktop/proje430\n",
            "CASE_POP = MKK\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------\n",
        "# PROJECT_ROOT detection\n",
        "# -------------------------\n",
        "def find_project_root(start=None) -> Path:\n",
        "    p = Path(start or Path.cwd()).resolve()\n",
        "    for parent in [p] + list(p.parents):\n",
        "        if (parent / \"data\").exists() or (parent / \".git\").exists() or (parent / \"requirements.txt\").exists():\n",
        "            return parent\n",
        "    return p\n",
        "\n",
        "PROJECT_ROOT = find_project_root()\n",
        "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
        "\n",
        "FIG_DIR = PROJECT_ROOT / \"results\" / \"figures\" / \"comparisons\"\n",
        "TAB_DIR = PROJECT_ROOT / \"results\" / \"tables\" / \"comparisons\"\n",
        "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "regions = [\"chr2_5Mb\", \"chr10_1Mb\"]\n",
        "eps_grid = [0.03, 0.1, 0.3, 1.0, 3.0, 10.0]\n",
        "\n",
        "methods = {\n",
        "    \"method1\": \"Method 1 (SNP Laplace DP)\",\n",
        "    \"method2\": \"Method 2 (Haploblock DP)\",\n",
        "    \"method3\": \"Method 3 (GRR LDP)\",\n",
        "}\n",
        "\n",
        "case_pop_json = PROJECT_ROOT / \"data\" / \"processed\" / \"hapmap\" / \"cohorts\" / \"hapmap_case_pop.json\"\n",
        "if not case_pop_json.exists():\n",
        "    raise FileNotFoundError(f\"Missing case_pop JSON: {case_pop_json}\")\n",
        "case_info = json.loads(case_pop_json.read_text())\n",
        "CASE_POP = case_info[\"case_pop\"]\n",
        "print(\"CASE_POP =\", CASE_POP)\n",
        "\n",
        "PVALUE_CUTOFF = 1e-3\n",
        "P_CLIP = 1e-6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "EOL while scanning string literal (409694631.py, line 22)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    return \"\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Output helpers\n",
        "# -------------------------\n",
        "def with_timestamp(path: Path) -> Path:\n",
        "    if not path.exists():\n",
        "        return path\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    return path.with_name(f\"{path.stem}_{ts}{path.suffix}\")\n",
        "\n",
        "\n",
        "def save_csv_no_overwrite(df: pd.DataFrame, path: Path) -> Path:\n",
        "    out = with_timestamp(path)\n",
        "    df.to_csv(out, index=False)\n",
        "    return out\n",
        "\n",
        "\n",
        "def df_to_markdown_simple(df: pd.DataFrame) -> str:\n",
        "    cols = list(df.columns)\n",
        "    header = \"| \" + \" | \".join(cols) + \" |\"\n",
        "    sep = \"| \" + \" | \".join([\"---\"] * len(cols)) + \" |\"\n",
        "    rows = []\n",
        "    for _, row in df.iterrows():\n",
        "        rows.append(\"| \" + \" | \".join(str(row[c]) for c in cols) + \" |\")\n",
        "    return \"\\n\".join([header, sep] + rows)\n",
        "\n",
        "\n",
        "def save_md_no_overwrite(text: str, path: Path) -> Path:\n",
        "    out = with_timestamp(path)\n",
        "    out.write_text(text)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Load per-seed CSVs if available\n",
        "# -------------------------\n",
        "def load_method_per_seed(method: str) -> pd.DataFrame:\n",
        "    table_dir = PROJECT_ROOT / \"results\" / \"tables\" / method\n",
        "    candidates = [\n",
        "        table_dir / f\"{method}_per_seed_{CASE_POP}.csv\",\n",
        "        table_dir / f\"{method}_per_seed.csv\",\n",
        "    ]\n",
        "    for p in candidates:\n",
        "        if p.exists():\n",
        "            df = pd.read_csv(p)\n",
        "            df[\"_source_csv\"] = str(p)\n",
        "            return df\n",
        "    return None\n",
        "\n",
        "def normalize_per_seed(method: str, df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    # Region column may already be present\n",
        "    if \"region\" not in df.columns:\n",
        "        raise ValueError(f\"Missing region column in {method} per-seed CSV\")\n",
        "\n",
        "    # Standardize metric columns\n",
        "    if method == \"method2\":\n",
        "        lr_col = \"lr_power_case_above_threshold\"\n",
        "    else:\n",
        "        lr_col = \"lr_power\"\n",
        "\n",
        "    if lr_col not in df.columns:\n",
        "        raise ValueError(f\"Missing {lr_col} in {method} per-seed CSV\")\n",
        "    if \"jaccard\" not in df.columns:\n",
        "        raise ValueError(f\"Missing jaccard in {method} per-seed CSV\")\n",
        "    if \"maf_mae\" not in df.columns:\n",
        "        raise ValueError(f\"Missing maf_mae in {method} per-seed CSV\")\n",
        "\n",
        "    df = df.rename(columns={\n",
        "        lr_col: \"lr_power\",\n",
        "        \"jaccard\": \"utility_jaccard\",\n",
        "        \"maf_mae\": \"distortion_mae\",\n",
        "    })\n",
        "    df[\"method\"] = method\n",
        "    df[\"method_label\"] = methods[method]\n",
        "    return df[[\"method\", \"method_label\", \"region\", \"eps\", \"seed\", \"lr_power\", \"utility_jaccard\", \"distortion_mae\"]]\n",
        "\n",
        "per_seed_frames = []\n",
        "missing_methods = []\n",
        "for method in methods:\n",
        "    df = load_method_per_seed(method)\n",
        "    if df is None:\n",
        "        missing_methods.append(method)\n",
        "        continue\n",
        "    per_seed_frames.append(normalize_per_seed(method, df))\n",
        "\n",
        "if missing_methods:\n",
        "    print(\"[WARN] Missing per-seed CSV for:\", \", \".join(missing_methods))\n",
        "\n",
        "df_runs = pd.concat(per_seed_frames, ignore_index=True) if per_seed_frames else pd.DataFrame()\n",
        "if not df_runs.empty:\n",
        "    df_runs = df_runs[df_runs[\"region\"].isin(regions)].reset_index(drop=True)\n",
        "    print(\"Loaded per-seed rows:\", len(df_runs))\n",
        "else:\n",
        "    print(\"No per-seed CSVs loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Fallback: discover NPZ runs (if per-seed CSV missing)\n",
        "# -------------------------\n",
        "def parse_eps_from_dir(name: str) -> float:\n",
        "    if not name.startswith(\"eps_\"):\n",
        "        raise ValueError(f\"Invalid eps dir: {name}\")\n",
        "    val = name[4:].replace(\"p\", \".\")\n",
        "    return float(val)\n",
        "\n",
        "def parse_seed_from_dir(name: str) -> int:\n",
        "    if not name.startswith(\"seed_\"):\n",
        "        raise ValueError(f\"Invalid seed dir: {name}\")\n",
        "    return int(name[5:])\n",
        "\n",
        "def discover_runs(method: str, region: str):\n",
        "    base = PROJECT_ROOT / \"data\" / \"derived\" / method\n",
        "    if not base.exists():\n",
        "        return []\n",
        "    pattern = str(base / \"eps_*\" / \"seed_*\" / \"*.npz\")\n",
        "    all_paths = [Path(p) for p in glob.glob(pattern)]\n",
        "\n",
        "    region_key = \"chr2\" if region.startswith(\"chr2\") else \"chr10\"\n",
        "    out = []\n",
        "    for p in all_paths:\n",
        "        name = p.name\n",
        "        if region_key not in name:\n",
        "            continue\n",
        "        if method in [\"method1\", \"method2\"] and \"case_maf_noisy\" not in name:\n",
        "            continue\n",
        "        if method == \"method3\" and (\"case_maf_ldp\" not in name and \"grr\" not in name and \"method3\" not in name):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            eps = parse_eps_from_dir(p.parent.parent.name)\n",
        "            seed = parse_seed_from_dir(p.parent.name)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        out.append({\"eps\": eps, \"seed\": seed, \"npz_path\": p})\n",
        "    return out\n",
        "\n",
        "def load_region_npz(path: Path) -> dict:\n",
        "    z = np.load(path, allow_pickle=True)\n",
        "    return {k: z[k] for k in z.files}\n",
        "\n",
        "def _pick_genotype_matrix(region: dict) -> np.ndarray:\n",
        "    for key in [\"G\", \"G_sub\", \"genotypes\", \"X\"]:\n",
        "        if key in region:\n",
        "            G = region[key]\n",
        "            if isinstance(G, np.ndarray) and G.ndim == 2:\n",
        "                return G\n",
        "    for v in region.values():\n",
        "        if isinstance(v, np.ndarray) and v.ndim == 2:\n",
        "            return v\n",
        "    raise ValueError(\"No genotype matrix found in region NPZ\")\n",
        "\n",
        "def _ensure_snps_by_individuals(G: np.ndarray) -> np.ndarray:\n",
        "    return G.T if G.shape[0] < G.shape[1] else G\n",
        "\n",
        "def compute_counts_and_maf(G: np.ndarray, idx: list):\n",
        "    sub = G[:, idx]\n",
        "    mask = sub >= 0\n",
        "    called = mask.sum(axis=1).astype(np.int32)\n",
        "    mac = np.where(mask, sub, 0).sum(axis=1).astype(np.float64)\n",
        "    denom = 2.0 * np.maximum(called, 1)\n",
        "    maf = mac / denom\n",
        "    return called, mac, maf\n",
        "\n",
        "def lr_scores(G_snps_x_ind: np.ndarray, cols: list, p_case: np.ndarray, p_ctrl: np.ndarray) -> np.ndarray:\n",
        "    p_case = np.clip(p_case, P_CLIP, 1.0 - P_CLIP)\n",
        "    p_ctrl = np.clip(p_ctrl, P_CLIP, 1.0 - P_CLIP)\n",
        "    Gsub = G_snps_x_ind[:, cols]\n",
        "    # log likelihoods\n",
        "    p0_case = (1.0 - p_case) ** 2\n",
        "    p1_case = 2.0 * p_case * (1.0 - p_case)\n",
        "    p2_case = p_case ** 2\n",
        "    p0_ctrl = (1.0 - p_ctrl) ** 2\n",
        "    p1_ctrl = 2.0 * p_ctrl * (1.0 - p_ctrl)\n",
        "    p2_ctrl = p_ctrl ** 2\n",
        "    scores = []\n",
        "    for j in range(Gsub.shape[1]):\n",
        "        g = Gsub[:, j]\n",
        "        mask = g >= 0\n",
        "        if mask.sum() == 0:\n",
        "            scores.append(0.0)\n",
        "            continue\n",
        "        gj = g[mask].astype(int)\n",
        "        ll_case = np.log(np.where(gj == 0, p0_case[mask], np.where(gj == 1, p1_case[mask], p2_case[mask])))\n",
        "        ll_ctrl = np.log(np.where(gj == 0, p0_ctrl[mask], np.where(gj == 1, p1_ctrl[mask], p2_ctrl[mask])))\n",
        "        scores.append(float(np.sum(ll_case - ll_ctrl)))\n",
        "    return np.array(scores, dtype=float)\n",
        "\n",
        "def chisq_pvalues_case_vs_control(mac_case, called_case, mac_ctrl, called_ctrl):\n",
        "    from scipy.stats import chi2_contingency\n",
        "    pvals = []\n",
        "    for i in range(len(mac_case)):\n",
        "        case_alt = mac_case[i]\n",
        "        case_ref = 2.0 * called_case[i] - case_alt\n",
        "        ctrl_alt = mac_ctrl[i]\n",
        "        ctrl_ref = 2.0 * called_ctrl[i] - ctrl_alt\n",
        "        table = np.array([[case_alt, case_ref], [ctrl_alt, ctrl_ref]], dtype=float)\n",
        "        try:\n",
        "            _, p, _, _ = chi2_contingency(table)\n",
        "        except Exception:\n",
        "            p = 1.0\n",
        "        pvals.append(p)\n",
        "    return np.array(pvals, dtype=float)\n",
        "\n",
        "def overlap_metrics(sig_true: np.ndarray, sig_noisy: np.ndarray):\n",
        "    inter = np.logical_and(sig_true, sig_noisy).sum()\n",
        "    union = np.logical_or(sig_true, sig_noisy).sum()\n",
        "    jaccard = float(inter / union) if union > 0 else 0.0\n",
        "    return jaccard\n",
        "\n",
        "def compute_metrics_from_npz(method: str, region: str, npz_path: Path):\n",
        "    z = np.load(npz_path, allow_pickle=True)\n",
        "    p_case = z[\"released_maf\"] if \"released_maf\" in z else z[\"noisy_maf\"]\n",
        "    true_maf = z[\"true_maf\"] if \"true_maf\" in z else None\n",
        "    case_train_idx = z[\"case_train_idx\"].astype(int).tolist() if \"case_train_idx\" in z else None\n",
        "    case_test_idx = z[\"case_test_idx\"].astype(int).tolist() if \"case_test_idx\" in z else None\n",
        "\n",
        "    region_info = case_info[\"regions\"][region]\n",
        "    case_region = load_region_npz(PROJECT_ROOT / region_info[\"case_region\"])\n",
        "    ceu_region = load_region_npz(PROJECT_ROOT / region_info[\"ceu_region\"])\n",
        "    ceu_control_idx = np.load(PROJECT_ROOT / region_info[\"ceu_control_npz\"], allow_pickle=True)[\"indices\"].astype(int).tolist()\n",
        "\n",
        "    G_case = _ensure_snps_by_individuals(_pick_genotype_matrix(case_region))\n",
        "    G_ceu = _ensure_snps_by_individuals(_pick_genotype_matrix(ceu_region))\n",
        "\n",
        "    if case_train_idx is None or case_test_idx is None:\n",
        "        # fallback: deterministic split by seed if possible\n",
        "        seed = int(z[\"seed\"]) if \"seed\" in z else 0\n",
        "        rng = np.random.default_rng(seed)\n",
        "        idx_all = list(range(G_case.shape[1]))\n",
        "        rng.shuffle(idx_all)\n",
        "        n_train = max(1, int(round(0.7 * len(idx_all))))\n",
        "        case_train_idx = idx_all[:n_train]\n",
        "        case_test_idx = idx_all[n_train:]\n",
        "\n",
        "    # true maf\n",
        "    called_case, mac_case, maf_case = compute_counts_and_maf(G_case, case_train_idx)\n",
        "    if true_maf is None:\n",
        "        true_maf = maf_case\n",
        "    # control\n",
        "    called_ctrl, mac_ctrl, maf_ctrl = compute_counts_and_maf(G_ceu, ceu_control_idx)\n",
        "\n",
        "    # distortion\n",
        "    distortion = float(np.mean(np.abs(p_case - true_maf)))\n",
        "\n",
        "    # privacy\n",
        "    scores_member = lr_scores(G_case, case_train_idx, p_case=p_case, p_ctrl=maf_ctrl)\n",
        "    scores_nonmember = lr_scores(G_case, case_test_idx, p_case=p_case, p_ctrl=maf_ctrl)\n",
        "    thresh = float(np.quantile(scores_nonmember, 0.95))\n",
        "    lr_power = float(np.mean(scores_member >= thresh))\n",
        "\n",
        "    # utility\n",
        "    mac_case_noisy = np.clip(np.rint(p_case * (2.0 * called_case)), 0.0, 2.0 * called_case)\n",
        "    p_true = chisq_pvalues_case_vs_control(mac_case, called_case, mac_ctrl, called_ctrl)\n",
        "    p_noisy = chisq_pvalues_case_vs_control(mac_case_noisy, called_case, mac_ctrl, called_ctrl)\n",
        "    sig_true = p_true <= PVALUE_CUTOFF\n",
        "    sig_noisy = p_noisy <= PVALUE_CUTOFF\n",
        "    jacc = overlap_metrics(sig_true, sig_noisy)\n",
        "\n",
        "    return lr_power, jacc, distortion\n",
        "\n",
        "fallback_rows = []\n",
        "if missing_methods:\n",
        "    for method in missing_methods:\n",
        "        if method == \"method2\":\n",
        "            print(\"[WARN] method2 missing per-seed CSV; skipping NPZ fallback to avoid mismatched cohorts.\")\n",
        "            continue\n",
        "        for region in regions:\n",
        "            runs = discover_runs(method, region)\n",
        "            if not runs:\n",
        "                print(f\"[WARN] No NPZ runs found for {method} {region}\")\n",
        "                continue\n",
        "            for run in runs:\n",
        "                lr_power, jacc, distortion = compute_metrics_from_npz(method, region, run[\"npz_path\"])\n",
        "                fallback_rows.append({\n",
        "                    \"method\": method,\n",
        "                    \"method_label\": methods[method],\n",
        "                    \"region\": region,\n",
        "                    \"eps\": run[\"eps\"],\n",
        "                    \"seed\": run[\"seed\"],\n",
        "                    \"lr_power\": lr_power,\n",
        "                    \"utility_jaccard\": jacc,\n",
        "                    \"distortion_mae\": distortion,\n",
        "                })\n",
        "\n",
        "if fallback_rows:\n",
        "    df_fallback = pd.DataFrame(fallback_rows)\n",
        "    df_runs = pd.concat([df_runs, df_fallback], ignore_index=True)\n",
        "    print(\"Added fallback NPZ rows:\", len(df_fallback))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Aggregate + save tables\n",
        "# -------------------------\n",
        "if df_runs.empty:\n",
        "    raise RuntimeError(\"No runs available to compare. Check per-seed CSVs or NPZ outputs.\")\n",
        "\n",
        "df_runs = df_runs[df_runs[\"region\"].isin(regions)].copy()\n",
        "df_runs[\"eps\"] = df_runs[\"eps\"].astype(float)\n",
        "\n",
        "agg = df_runs.groupby([\"method\", \"method_label\", \"region\", \"eps\"])[[\"lr_power\", \"utility_jaccard\", \"distortion_mae\"]]\n",
        "df_agg = agg.agg([\"mean\", \"std\"]).reset_index()\n",
        "df_agg.columns = [c[0] if c[1] == \"\" else f\"{c[0]}_{c[1]}\" for c in df_agg.columns.to_flat_index()]\n",
        "\n",
        "out_all = save_csv_no_overwrite(df_runs, TAB_DIR / \"all_runs.csv\")\n",
        "out_agg = save_csv_no_overwrite(df_agg, TAB_DIR / \"agg_mean_std.csv\")\n",
        "print(\"Saved:\", out_all.relative_to(PROJECT_ROOT))\n",
        "print(\"Saved:\", out_agg.relative_to(PROJECT_ROOT))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Figures per region\n",
        "# -------------------------\n",
        "def plot_metric(region: str, metric: str, ylabel: str, title_prefix: str, filename_prefix: str):\n",
        "    sub = df_agg[df_agg[\"region\"] == region].copy()\n",
        "    if sub.empty:\n",
        "        print(f\"[WARN] No data for {region}\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    for method, label in methods.items():\n",
        "        msub = sub[sub[\"method\"] == method].sort_values(\"eps\")\n",
        "        if msub.empty:\n",
        "            continue\n",
        "        plt.plot(msub[\"eps\"], msub[f\"{metric}_mean\"], marker=\"o\", label=label)\n",
        "\n",
        "    plt.xscale(\"log\")\n",
        "    plt.xlabel(\"epsilon (log scale)\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(f\"{title_prefix} - {region}\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    out = with_timestamp(FIG_DIR / f\"{filename_prefix}_{region}.png\")\n",
        "    plt.savefig(out, dpi=200)\n",
        "    plt.close()\n",
        "    print(\"Saved:\", out.relative_to(PROJECT_ROOT))\n",
        "\n",
        "for region in regions:\n",
        "    plot_metric(\n",
        "        region,\n",
        "        metric=\"lr_power\",\n",
        "        ylabel=\"LR power (members above 95% nonmember threshold) down\",\n",
        "        title_prefix=\"Privacy vs eps (LR power)\",\n",
        "        filename_prefix=\"privacy\",\n",
        "    )\n",
        "    plot_metric(\n",
        "        region,\n",
        "        metric=\"utility_jaccard\",\n",
        "        ylabel=\"Jaccard(sig_true, sig_noisy) up\",\n",
        "        title_prefix=\"Utility vs eps (GWAS overlap)\",\n",
        "        filename_prefix=\"utility\",\n",
        "    )\n",
        "    plot_metric(\n",
        "        region,\n",
        "        metric=\"distortion_mae\",\n",
        "        ylabel=\"MAF MAE(|p_true - p_noisy|) down\",\n",
        "        title_prefix=\"Distortion vs eps (MAF MAE)\",\n",
        "        filename_prefix=\"distortion\",\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Compact tables for report\n",
        "# -------------------------\n",
        "def fmt_mean_std(mean_val, std_val):\n",
        "    if np.isnan(mean_val):\n",
        "        return \"NA\"\n",
        "    if np.isnan(std_val):\n",
        "        return f\"{mean_val:.4g}\"\n",
        "    return f\"{mean_val:.4g}+/-{std_val:.2g}\"\n",
        "\n",
        "target_eps = [0.1, 1.0, 10.0]\n",
        "for region in regions:\n",
        "    sub = df_agg[df_agg[\"region\"] == region].copy()\n",
        "    if sub.empty:\n",
        "        continue\n",
        "    sub = sub[sub[\"eps\"].isin(target_eps)]\n",
        "    if sub.empty:\n",
        "        print(f\"[WARN] No target eps present for {region}\")\n",
        "        continue\n",
        "\n",
        "    rows = []\n",
        "    for method, label in methods.items():\n",
        "        msub = sub[sub[\"method\"] == method]\n",
        "        if msub.empty:\n",
        "            continue\n",
        "        for eps in sorted(msub[\"eps\"].unique()):\n",
        "            row = msub[msub[\"eps\"] == eps].iloc[0]\n",
        "            rows.append({\n",
        "                \"method\": label,\n",
        "                \"eps\": eps,\n",
        "                \"lr_power\": fmt_mean_std(row[\"lr_power_mean\"], row[\"lr_power_std\"]),\n",
        "                \"utility\": fmt_mean_std(row[\"utility_jaccard_mean\"], row[\"utility_jaccard_std\"]),\n",
        "                \"distortion\": fmt_mean_std(row[\"distortion_mae_mean\"], row[\"distortion_mae_std\"]),\n",
        "            })\n",
        "\n",
        "    out_df = pd.DataFrame(rows)\n",
        "    out_csv = save_csv_no_overwrite(out_df, TAB_DIR / f\"table_{region}_eps_0p1_1_10.csv\")\n",
        "    out_md = save_md_no_overwrite(df_to_markdown_simple(out_df), TAB_DIR / f\"table_{region}_eps_0p1_1_10.md\")\n",
        "    print(\"Saved:\", out_csv.relative_to(PROJECT_ROOT))\n",
        "    print(\"Saved:\", out_md.relative_to(PROJECT_ROOT))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Scoreboard at eps=1.0 (optional)\n",
        "# -------------------------\n",
        "rows = []\n",
        "for region in regions:\n",
        "    sub = df_agg[(df_agg[\"region\"] == region) & (df_agg[\"eps\"] == 1.0)].copy()\n",
        "    if sub.empty:\n",
        "        continue\n",
        "    # check all methods present\n",
        "    if len(set(sub[\"method\"])) < len(methods):\n",
        "        print(f\"[WARN] eps=1.0 missing some methods for {region}\")\n",
        "    for _, r in sub.iterrows():\n",
        "        rows.append({\n",
        "            \"region\": region,\n",
        "            \"method\": r[\"method_label\"],\n",
        "            \"lr_power_mean\": r[\"lr_power_mean\"],\n",
        "            \"utility_mean\": r[\"utility_jaccard_mean\"],\n",
        "            \"distortion_mean\": r[\"distortion_mae_mean\"],\n",
        "        })\n",
        "\n",
        "if rows:\n",
        "    df_score = pd.DataFrame(rows)\n",
        "    out_score = save_csv_no_overwrite(df_score, TAB_DIR / \"scoreboard_eps_1p0.csv\")\n",
        "    print(\"Saved:\", out_score.relative_to(PROJECT_ROOT))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Outputs written to:\")\n",
        "print(\" Figures:\", FIG_DIR.relative_to(PROJECT_ROOT))\n",
        "print(\" Tables:\", TAB_DIR.relative_to(PROJECT_ROOT))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}