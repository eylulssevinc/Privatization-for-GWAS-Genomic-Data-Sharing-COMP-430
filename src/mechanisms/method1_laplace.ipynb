{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349ed843",
   "metadata": {},
   "source": [
    "# Method 1 Method 1: Laplace on MAF vector (YRI train vs YRI test)\n",
    "\n",
    "This notebook implements Method 1 as requested: DP noise on the **MAF vector** released from **YRI_train** only, with membership inference evaluated **within YRI** (train vs test) and CEU as public control reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0013cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = /Users/erkmenerken/Desktop/proje430\n",
      "COHORTS_PATH = /Users/erkmenerken/Desktop/proje430/data/processed/hapmap/cohorts/hapmap_CEU_control_test__YRI_case.json\n",
      "EPS_LIST = [0.03, 0.1, 0.3, 1.0, 3.0, 10.0]\n",
      "SEED_LIST = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "PVALUE_CUTOFF = 0.001\n",
      "SHRINK_ALPHA = 1.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# Robust PROJECT_ROOT detection\n",
    "# -------------------------\n",
    "def find_project_root(start=None) -> Path:\n",
    "    p = Path(start or Path.cwd()).resolve()\n",
    "    for parent in [p] + list(p.parents):\n",
    "        if (parent / \".git\").exists() or (parent / \"requirements.txt\").exists():\n",
    "            return parent\n",
    "    return p\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "PROC_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"hapmap\"\n",
    "REGIONS_DIR = PROC_DIR / \"regions\"\n",
    "COHORTS_PATH = PROC_DIR / \"cohorts\" / \"hapmap_CEU_control_test__YRI_case.json\"\n",
    "\n",
    "DERIVED_DIR = PROJECT_ROOT / \"data\" / \"derived\" / \"method1\"\n",
    "FIG_DIR = PROJECT_ROOT / \"results\" / \"figures\" / \"method1\"\n",
    "TABLE_DIR = PROJECT_ROOT / \"results\" / \"tables\" / \"method1\"\n",
    "\n",
    "for d in [DERIVED_DIR, FIG_DIR, TABLE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "EPS_LIST = [0.03, 0.1, 0.3, 1.0, 3.0, 10.0]\n",
    "SEED_LIST = list(range(10))\n",
    "PVALUE_CUTOFF = 1e-3\n",
    "ALPHA_TEST_EXCEED = 0.05\n",
    "P_CLIP = 1e-6\n",
    "\n",
    "\n",
    "SHRINK_ALPHA = 1.0\n",
    "\n",
    "REGION_FILES = {\n",
    "    \"chr2_5Mb\": {\n",
    "        \"ceu\": REGIONS_DIR / \"CEU_chr2_5Mb.common_with_YRI.npz\",\n",
    "        \"yri\": REGIONS_DIR / \"YRI_chr2_5Mb.common_with_CEU.npz\",\n",
    "    },\n",
    "    \"chr10_1Mb\": {\n",
    "        \"ceu\": REGIONS_DIR / \"CEU_chr10_1Mb.common_with_YRI.npz\",\n",
    "        \"yri\": REGIONS_DIR / \"YRI_chr10_1Mb.common_with_CEU.npz\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "print(\"COHORTS_PATH =\", COHORTS_PATH)\n",
    "print(\"EPS_LIST =\", EPS_LIST)\n",
    "print(\"SEED_LIST =\", SEED_LIST)\n",
    "print(\"PVALUE_CUTOFF =\", PVALUE_CUTOFF)\n",
    "print(\"SHRINK_ALPHA =\", SHRINK_ALPHA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b169c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded chr2_5Mb CEU: data/processed/hapmap/regions/CEU_chr2_5Mb.common_with_YRI.npz\n",
      "Loaded chr2_5Mb YRI: data/processed/hapmap/regions/YRI_chr2_5Mb.common_with_CEU.npz\n",
      "Loaded chr10_1Mb CEU: data/processed/hapmap/regions/CEU_chr10_1Mb.common_with_YRI.npz\n",
      "Loaded chr10_1Mb YRI: data/processed/hapmap/regions/YRI_chr10_1Mb.common_with_CEU.npz\n",
      "CEU control idx count: 120\n",
      "YRI case idx count (pool): 176\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Load regions + cohorts\n",
    "# -------------------------\n",
    "def load_region_npz(path: Path) -> Dict[str, np.ndarray]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing region file: {path}\")\n",
    "    z = np.load(path, allow_pickle=True)\n",
    "    return {k: z[k] for k in z.files}\n",
    "\n",
    "def _pick_genotype_matrix(region: Dict[str, np.ndarray]) -> np.ndarray:\n",
    "    for key in [\"G\", \"G_sub\", \"genotypes\", \"X\"]:\n",
    "        if key in region:\n",
    "            G = region[key]\n",
    "            if isinstance(G, np.ndarray) and G.ndim == 2:\n",
    "                return G\n",
    "    for k, v in region.items():\n",
    "        if isinstance(v, np.ndarray) and v.ndim == 2:\n",
    "            return v\n",
    "    raise ValueError(\"No 2D genotype matrix found in region npz.\")\n",
    "\n",
    "def _ensure_snps_by_individuals(G: np.ndarray) -> np.ndarray:\n",
    "    # Expect shape (n_snps, n_individuals). If likely transposed, fix it.\n",
    "    if G.shape[0] < G.shape[1]:\n",
    "        return G.T\n",
    "    return G\n",
    "\n",
    "regions = {}\n",
    "for region_tag, paths in REGION_FILES.items():\n",
    "    regions[region_tag] = {\n",
    "        \"ceu\": load_region_npz(paths[\"ceu\"]),\n",
    "        \"yri\": load_region_npz(paths[\"yri\"]),\n",
    "    }\n",
    "    print(f\"Loaded {region_tag} CEU: {paths['ceu'].relative_to(PROJECT_ROOT)}\")\n",
    "    print(f\"Loaded {region_tag} YRI: {paths['yri'].relative_to(PROJECT_ROOT)}\")\n",
    "\n",
    "cohorts = json.loads(COHORTS_PATH.read_text())\n",
    "for k in [\"control\", \"test\", \"case\"]:\n",
    "    if k not in cohorts:\n",
    "        raise KeyError(f\"Missing '{k}' in cohorts JSON\")\n",
    "\n",
    "ceu_control_idx = list(cohorts[\"control\"][\"indices_in_ceu_matrix\"])\n",
    "yri_case_idx_all = list(cohorts[\"case\"][\"indices_in_yri_matrix\"])\n",
    "\n",
    "print(\"CEU control idx count:\", len(ceu_control_idx))\n",
    "print(\"YRI case idx count (pool):\", len(yri_case_idx_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cedf7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def compute_counts_and_maf(G_snps_x_ind: np.ndarray, cols: List[int]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    sub = G_snps_x_ind[:, cols]\n",
    "    called = sub != -1\n",
    "    called_n = called.sum(axis=1).astype(np.int32)\n",
    "    sub_nonmiss = np.where(called, sub, 0)\n",
    "    mac = sub_nonmiss.sum(axis=1).astype(np.float64)\n",
    "    denom = 2.0 * np.maximum(called_n, 1)\n",
    "    maf = mac / denom\n",
    "    return called_n, mac, maf\n",
    "\n",
    "def noisy_counts_from_maf(maf: np.ndarray, called_n: np.ndarray) -> np.ndarray:\n",
    "    raw = np.rint(maf * (2.0 * called_n))\n",
    "    return np.clip(raw, 0.0, 2.0 * called_n).astype(np.float64)\n",
    "\n",
    "def laplace_mechanism_maf_vector(maf: np.ndarray, called_n: np.ndarray, eps: float, rng: np.random.Generator):\n",
    "    n_min = int(np.min(called_n))\n",
    "    if n_min < 1:\n",
    "        raise RuntimeError(\"n_min < 1; cannot compute sensitivity for MAF vector.\")\n",
    "    # Sensitivity derivation: each SNP frequency changes by at most 1/n, so L1 sensitivity is N/n.\n",
    "    delta1 = len(maf) / n_min\n",
    "    scale = delta1 / eps\n",
    "    noisy = maf + rng.laplace(loc=0.0, scale=scale, size=maf.shape[0])\n",
    "    noisy = np.clip(noisy, 0.0, 1.0)\n",
    "    return noisy, n_min, delta1, scale\n",
    "\n",
    "def chisq_pvalues_case_vs_control(mac_case: np.ndarray, called_case: np.ndarray,\n",
    "                                 mac_ctrl: np.ndarray, called_ctrl: np.ndarray) -> np.ndarray:\n",
    "    n = mac_case.shape[0]\n",
    "    pvals = np.ones(n, dtype=np.float64)\n",
    "    for j in range(n):\n",
    "        minor_case = mac_case[j]\n",
    "        major_case = 2.0 * called_case[j] - minor_case\n",
    "        minor_ctrl = mac_ctrl[j]\n",
    "        major_ctrl = 2.0 * called_ctrl[j] - minor_ctrl\n",
    "        if called_case[j] <= 0 or called_ctrl[j] <= 0:\n",
    "            pvals[j] = 1.0\n",
    "            continue\n",
    "        if major_case < 0 or major_ctrl < 0:\n",
    "            pvals[j] = 1.0\n",
    "            continue\n",
    "        table = np.array([[minor_case, major_case], [minor_ctrl, major_ctrl]], dtype=np.float64)\n",
    "        if np.any(table.sum(axis=1) <= 0) or np.any(table.sum(axis=0) <= 0):\n",
    "            pvals[j] = 1.0\n",
    "            continue\n",
    "        try:\n",
    "            _, p, _, _ = chi2_contingency(table, correction=False)\n",
    "            pvals[j] = float(p)\n",
    "        except Exception:\n",
    "            pvals[j] = 1.0\n",
    "    return pvals\n",
    "\n",
    "def overlap_metrics(sig_true: np.ndarray, sig_noisy: np.ndarray) -> Dict[str, float]:\n",
    "    a = sig_true.astype(bool)\n",
    "    b = sig_noisy.astype(bool)\n",
    "    tp = int(np.sum(a & b))\n",
    "    fp = int(np.sum(~a & b))\n",
    "    fn = int(np.sum(a & ~b))\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    jaccard = tp / (tp + fp + fn) if (tp + fp + fn) else 0.0\n",
    "    return {\n",
    "        \"true_sig\": int(np.sum(a)),\n",
    "        \"noisy_sig\": int(np.sum(b)),\n",
    "        \"tp\": tp,\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"jaccard\": float(jaccard),\n",
    "    }\n",
    "\n",
    "def genotype_log_prob_hwe(g: np.ndarray, p: np.ndarray) -> np.ndarray:\n",
    "    p = np.clip(p, P_CLIP, 1.0 - P_CLIP)\n",
    "    q = 1.0 - p\n",
    "    logP0 = 2.0 * np.log(q)\n",
    "    logP1 = np.log(2.0) + np.log(p) + np.log(q)\n",
    "    logP2 = 2.0 * np.log(p)\n",
    "    out = np.zeros_like(p, dtype=np.float64)\n",
    "    out = np.where(g == 0, logP0, out)\n",
    "    out = np.where(g == 1, logP1, out)\n",
    "    out = np.where(g == 2, logP2, out)\n",
    "    return out\n",
    "\n",
    "def lr_scores(G_snps_x_ind: np.ndarray, cols: List[int], p_case: np.ndarray, p_ctrl: np.ndarray) -> np.ndarray:\n",
    "    G = G_snps_x_ind[:, cols]\n",
    "    n_ind = G.shape[1]\n",
    "    scores = np.zeros(n_ind, dtype=np.float64)\n",
    "    for i in range(n_ind):\n",
    "        g = G[:, i]\n",
    "        mask = g >= 0\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        log_case = genotype_log_prob_hwe(g[mask], p_case[mask])\n",
    "        log_ctrl = genotype_log_prob_hwe(g[mask], p_ctrl[mask])\n",
    "        scores[i] = float(np.sum(log_case - log_ctrl))\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc19431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[chr2_5Mb] n_snps=297 | CEU ctrl=120 | YRI pool=176\n",
      "[chr10_1Mb] n_snps=581 | CEU ctrl=120 | YRI pool=176\n",
      "Saved per-seed table -> results/tables/method1/method1_per_seed.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Main loop: Method 1\n",
    "# -------------------------\n",
    "def split_train_test(indices: List[int], seed: int, frac_train: float = 0.7) -> Tuple[List[int], List[int]]:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    shuffled = list(rng.permutation(indices))\n",
    "    n = len(shuffled)\n",
    "    n_train = int(round(n * frac_train))\n",
    "    n_train = max(1, min(n - 1, n_train))\n",
    "    return shuffled[:n_train], shuffled[n_train:]\n",
    "\n",
    "def eps_dir(eps: float) -> Path:\n",
    "    s = str(eps).replace(\".\", \"p\")\n",
    "    return DERIVED_DIR / f\"eps_{s}\"\n",
    "\n",
    "records = []\n",
    "hist_cache = {}\n",
    "\n",
    "for region_tag, region_pair in regions.items():\n",
    "    G_ceu = _ensure_snps_by_individuals(_pick_genotype_matrix(region_pair[\"ceu\"]))\n",
    "    G_yri = _ensure_snps_by_individuals(_pick_genotype_matrix(region_pair[\"yri\"]))\n",
    "\n",
    "    n_snps, n_ceu = G_ceu.shape\n",
    "    n_snps_yri, n_yri = G_yri.shape\n",
    "    if n_snps != n_snps_yri:\n",
    "        raise RuntimeError(f\"SNP count mismatch in {region_tag}: CEU={n_snps}, YRI={n_snps_yri}\")\n",
    "\n",
    "    ceu_ctrl_idx = [i for i in ceu_control_idx if i < n_ceu]\n",
    "    yri_pool = [i for i in yri_case_idx_all if i < n_yri]\n",
    "\n",
    "    if len(ceu_ctrl_idx) == 0:\n",
    "        raise RuntimeError(f\"No CEU control indices for {region_tag}\")\n",
    "    if len(yri_pool) == 0:\n",
    "        raise RuntimeError(f\"No YRI case indices for {region_tag}\")\n",
    "\n",
    "    print(f\"[{region_tag}] n_snps={n_snps} | CEU ctrl={len(ceu_ctrl_idx)} | YRI pool={len(yri_pool)}\")\n",
    "\n",
    "    # Control MAF (public reference)\n",
    "    called_ctrl, mac_ctrl, maf_ctrl = compute_counts_and_maf(G_ceu, ceu_ctrl_idx)\n",
    "\n",
    "    for eps in EPS_LIST:\n",
    "        outdir = eps_dir(eps)\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for seed in SEED_LIST:\n",
    "            rng = np.random.default_rng(seed)\n",
    "            yri_train_idx, yri_test_idx = split_train_test(yri_pool, seed=seed, frac_train=0.7)\n",
    "\n",
    "            # True case from YRI train\n",
    "            called_case, mac_case, maf_case = compute_counts_and_maf(G_yri, yri_train_idx)\n",
    "\n",
    "            # DP release on MAF vector\n",
    "            noisy_maf, n_min_used, delta1_used, scale_used = laplace_mechanism_maf_vector(\n",
    "                maf=maf_case,\n",
    "                called_n=called_case,\n",
    "                eps=eps,\n",
    "                rng=rng,\n",
    "            )\n",
    "            released_maf = SHRINK_ALPHA * noisy_maf + (1.0 - SHRINK_ALPHA) * maf_ctrl\n",
    "            released_maf = np.clip(released_maf, 0.0, 1.0)\n",
    "\n",
    "            noisy_mac_safe = noisy_counts_from_maf(released_maf, called_case)\n",
    "\n",
    "            # Privacy: LR scores within YRI\n",
    "            scores_member = lr_scores(G_yri, yri_train_idx, p_case=released_maf, p_ctrl=maf_ctrl)\n",
    "            scores_nonmember = lr_scores(G_yri, yri_test_idx, p_case=released_maf, p_ctrl=maf_ctrl)\n",
    "            thresh = float(np.quantile(scores_nonmember, 1.0 - ALPHA_TEST_EXCEED))\n",
    "            lr_power = float(np.mean(scores_member >= thresh))\n",
    "\n",
    "            # Utility: GWAS overlap (true vs noisy)\n",
    "            p_true = chisq_pvalues_case_vs_control(mac_case, called_case, mac_ctrl, called_ctrl)\n",
    "            p_noisy = chisq_pvalues_case_vs_control(noisy_mac_safe, called_case, mac_ctrl, called_ctrl)\n",
    "            sig_true = p_true <= PVALUE_CUTOFF\n",
    "            sig_noisy = p_noisy <= PVALUE_CUTOFF\n",
    "            ov = overlap_metrics(sig_true, sig_noisy)\n",
    "\n",
    "            # DP distortion diagnostics\n",
    "            maf_mse = float(np.mean((released_maf - maf_case) ** 2))\n",
    "            maf_mae = float(np.mean(np.abs(released_maf - maf_case)))\n",
    "            clip_frac = float(np.mean((released_maf <= 0.0) | (released_maf >= 1.0)))\n",
    "\n",
    "            # Save per-seed outputs\n",
    "            seed_dir = outdir / f\"seed_{seed}\"\n",
    "            seed_dir.mkdir(parents=True, exist_ok=True)\n",
    "            out_path = seed_dir / f\"{region_tag}.case_maf_noisy.npz\"\n",
    "            np.savez_compressed(\n",
    "                out_path,\n",
    "                noisy_maf=noisy_maf,\n",
    "                released_maf=released_maf,\n",
    "                noisy_mac_safe=noisy_mac_safe,\n",
    "                eps=float(eps),\n",
    "                seed=int(seed),\n",
    "                region_tag=region_tag,\n",
    "                n_min_used=int(n_min_used),\n",
    "                delta1_used=float(delta1_used),\n",
    "                scale_used=float(scale_used),\n",
    "                shrink_alpha=float(SHRINK_ALPHA),\n",
    "                yri_train_idx=np.array(yri_train_idx, dtype=np.int32),\n",
    "                yri_test_idx=np.array(yri_test_idx, dtype=np.int32),\n",
    "            )\n",
    "\n",
    "            # Cache histogram inputs for eps=1.0 seed=0\n",
    "            if abs(eps - 1.0) < 1e-9 and seed == 0:\n",
    "                hist_cache[region_tag] = (scores_member, scores_nonmember)\n",
    "\n",
    "            rec = {\n",
    "                \"seed\": int(seed),\n",
    "                \"eps\": float(eps),\n",
    "                \"region\": region_tag,\n",
    "                \"n_snps\": int(n_snps),\n",
    "                \"n_train\": int(len(yri_train_idx)),\n",
    "                \"n_test\": int(len(yri_test_idx)),\n",
    "                \"n_ctrl\": int(len(ceu_ctrl_idx)),\n",
    "                \"n_min\": int(n_min_used),\n",
    "                \"delta1\": float(delta1_used),\n",
    "                \"scale\": float(scale_used),\n",
    "                # privacy\n",
    "                \"lr_threshold_test_95pct\": thresh,\n",
    "                \"lr_power\": lr_power,\n",
    "                \"lr_member_mean\": float(np.mean(scores_member)),\n",
    "                \"lr_nonmember_mean\": float(np.mean(scores_nonmember)),\n",
    "                # utility\n",
    "                **ov,\n",
    "                \"maf_mse\": maf_mse,\n",
    "                \"maf_mae\": maf_mae,\n",
    "                \"clip_frac\": clip_frac,\n",
    "                \"shrink_alpha\": float(SHRINK_ALPHA),\n",
    "            }\n",
    "            records.append(rec)\n",
    "\n",
    "df_per_seed = pd.DataFrame(records)\n",
    "df_per_seed = df_per_seed.sort_values([\"region\", \"eps\", \"seed\"]).reset_index(drop=True)\n",
    "\n",
    "per_seed_csv = TABLE_DIR / \"method1_per_seed.csv\"\n",
    "df_per_seed.to_csv(per_seed_csv, index=False)\n",
    "print(\"Saved per-seed table ->\", per_seed_csv.relative_to(PROJECT_ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad1c162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary table -> results/tables/method1/method1_summary.csv\n",
      "Plots saved under results/figures/method1\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Aggregate summary + plots\n",
    "# -------------------------\n",
    "\n",
    "group_cols = [\"region\", \"eps\"]\n",
    "agg_cols = [\"lr_power\", \"jaccard\", \"precision\", \"recall\", \"maf_mae\", \"maf_mse\", \"clip_frac\"]\n",
    "\n",
    "summary = df_per_seed.groupby(group_cols)[agg_cols].agg([\"mean\", \"std\"]).reset_index()\n",
    "\n",
    "# Flatten columns\n",
    "summary.columns = [c[0] if c[1] == \"\" else f\"{c[0]}_{c[1]}\" for c in summary.columns.to_flat_index()]\n",
    "\n",
    "summary_csv = TABLE_DIR / \"method1_summary.csv\"\n",
    "summary.to_csv(summary_csv, index=False)\n",
    "print(\"Saved summary table ->\", summary_csv.relative_to(PROJECT_ROOT))\n",
    "\n",
    "# ---- Plot curves per region ----\n",
    "for region_tag in summary[\"region\"].unique():\n",
    "    sub = summary[summary[\"region\"] == region_tag].sort_values(\"eps\")\n",
    "    eps = sub[\"eps\"].to_numpy()\n",
    "    lr_mean = sub[\"lr_power_mean\"].to_numpy()\n",
    "\n",
    "    # Privacy curve (mean only)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(eps, lr_mean, marker=\"o\", label=\"LR power\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"epsilon (log scale)\")\n",
    "    plt.ylabel(\"LR power (members above 95% nonmember threshold)\")\n",
    "    plt.title(f\"Method 1 Privacy (LR power) — {region_tag}\")\n",
    "    plt.legend()\n",
    "    out_path = FIG_DIR / f\"{region_tag}.privacy_lr_power.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Utility curve (Jaccard)\n",
    "    jac_mean = sub[\"jaccard_mean\"].to_numpy()\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(eps, jac_mean, marker=\"o\", label=\"Jaccard\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"epsilon (log scale)\")\n",
    "    plt.ylabel(\"Jaccard(sig_true, sig_noisy)\")\n",
    "    plt.title(f\"Method 1 Utility (GWAS overlap) — {region_tag}\")\n",
    "    plt.legend()\n",
    "    out_path = FIG_DIR / f\"{region_tag}.utility_jaccard.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "    # DP distortion curve (MAE)\n",
    "    mae_mean = sub[\"maf_mae_mean\"].to_numpy()\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(eps, mae_mean, marker=\"o\", label=\"MAF MAE\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"epsilon (log scale)\")\n",
    "    plt.ylabel(\"MAF MAE\")\n",
    "    plt.title(f\"Method 1 DP Distortion — {region_tag}\")\n",
    "    plt.legend()\n",
    "    out_path = FIG_DIR / f\"{region_tag}.dp_distortion.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "    # LR histogram for eps=1.0 seed=0\n",
    "    if region_tag in hist_cache:\n",
    "        scores_member, scores_nonmember = hist_cache[region_tag]\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.hist(scores_member, bins=25, alpha=0.6, label=\"YRI train (members)\")\n",
    "        plt.hist(scores_nonmember, bins=25, alpha=0.6, label=\"YRI test (nonmembers)\")\n",
    "        plt.xlabel(\"LR score\")\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.title(f\"LR score distributions — {region_tag} (eps=1.0)\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        out_path = FIG_DIR / f\"{region_tag}.lr_hist_eps_1p0.png\"\n",
    "        plt.savefig(out_path)\n",
    "        plt.close()\n",
    "\n",
    "print(\"Plots saved under\", FIG_DIR.relative_to(PROJECT_ROOT))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
