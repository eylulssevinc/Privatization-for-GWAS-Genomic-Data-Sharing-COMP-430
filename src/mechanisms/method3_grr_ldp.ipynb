{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Method 3: Local DP via GRR (per-individual single-SNP reporting)\n",
        "\n",
        "Implements the LDP GRR mechanism where each CASE_POP case individual reports a single SNP genotype (0/1/2) with generalized randomized response. Debiases per-SNP genotype distributions to estimate case MAF.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ROOT = /Users/erkmenerken/Desktop/proje430\n",
            "CASE_POP = MKK\n",
            "COHORTS_JSON = /Users/erkmenerken/Desktop/proje430/data/processed/hapmap/cohorts/hapmap_case_pop.json\n",
            "EPS_LIST = [0.03, 0.1, 0.3, 1.0, 3.0, 10.0]\n",
            "SEED_LIST = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "REPORT_K = 1\n",
            "Chance baseline LR power ~ 0.05\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Robust PROJECT_ROOT detection\n",
        "\n",
        "\n",
        "def find_project_root(start=None) -> Path:\n",
        "    p = Path(start or Path.cwd()).resolve()\n",
        "    for parent in [p] + list(p.parents):\n",
        "        if (parent / \".git\").exists() or (parent / \"requirements.txt\").exists():\n",
        "            return parent\n",
        "    return p\n",
        "\n",
        "PROJECT_ROOT = find_project_root()\n",
        "PROC_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"hapmap\"\n",
        "REGIONS_DIR = PROC_DIR / \"regions\"\n",
        "COHORTS_JSON = PROC_DIR / \"cohorts\" / \"hapmap_case_pop.json\"\n",
        "\n",
        "DERIVED_DIR = PROJECT_ROOT / \"data\" / \"derived\" / \"method3\"\n",
        "FIG_DIR = PROJECT_ROOT / \"results\" / \"figures\" / \"method3\"\n",
        "TABLE_DIR = PROJECT_ROOT / \"results\" / \"tables\" / \"method3\"\n",
        "\n",
        "for d in [DERIVED_DIR, FIG_DIR, TABLE_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if not COHORTS_JSON.exists():\n",
        "    raise FileNotFoundError(f\"Missing case_pop config: {COHORTS_JSON}\")\n",
        "\n",
        "case_info = json.loads(COHORTS_JSON.read_text())\n",
        "CASE_POP = case_info[\"case_pop\"]\n",
        "\n",
        "EPS_LIST = [0.03, 0.1, 0.3, 1.0, 3.0, 10.0]\n",
        "SEED_LIST = list(range(30))\n",
        "PVALUE_CUTOFF = 1e-3\n",
        "ALPHA_TEST_EXCEED = 0.05\n",
        "P_CLIP = 1e-6\n",
        "REPORT_K = 1\n",
        "\n",
        "REGION_FILES = {}\n",
        "for region_tag, info in case_info[\"regions\"].items():\n",
        "    REGION_FILES[region_tag] = {\n",
        "        \"ceu\": PROJECT_ROOT / info[\"ceu_region\"],\n",
        "        \"case\": PROJECT_ROOT / info[\"case_region\"],\n",
        "        \"ceu_control_npz\": PROJECT_ROOT / info[\"ceu_control_npz\"],\n",
        "    }\n",
        "\n",
        "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
        "print(\"CASE_POP =\", CASE_POP)\n",
        "print(\"COHORTS_JSON =\", COHORTS_JSON)\n",
        "print(\"EPS_LIST =\", EPS_LIST)\n",
        "print(\"SEED_LIST =\", SEED_LIST)\n",
        "print(\"REPORT_K =\", REPORT_K)\n",
        "print(\"Chance baseline LR power ~\", ALPHA_TEST_EXCEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded chr2_5Mb CEU: data/processed/hapmap/regions/CEU_chr2_5Mb.common_with_MKK.npz\n",
            "Loaded chr2_5Mb CASE: data/processed/hapmap/regions/MKK_chr2_5Mb.common_with_CEU.npz\n",
            "CEU control idx count: 165 | CASE pool: 171\n",
            "Loaded chr10_1Mb CEU: data/processed/hapmap/regions/CEU_chr10_1Mb.common_with_MKK.npz\n",
            "Loaded chr10_1Mb CASE: data/processed/hapmap/regions/MKK_chr10_1Mb.common_with_CEU.npz\n",
            "CEU control idx count: 165 | CASE pool: 171\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load regions + cohorts\n",
        "\n",
        "def load_region_npz(path: Path) -> Dict[str, np.ndarray]:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Missing region file: {path}\")\n",
        "    z = np.load(path, allow_pickle=True)\n",
        "    return {k: z[k] for k in z.files}\n",
        "\n",
        "\n",
        "def load_indices_npz(path: Path) -> List[int]:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Missing cohort file: {path}\")\n",
        "    z = np.load(path, allow_pickle=True)\n",
        "    return list(z[\"indices\"].astype(int))\n",
        "\n",
        "\n",
        "def _pick_genotype_matrix(region: Dict[str, np.ndarray]) -> np.ndarray:\n",
        "    for key in [\"G\", \"G_sub\", \"genotypes\", \"X\"]:\n",
        "        if key in region:\n",
        "            G = region[key]\n",
        "            if isinstance(G, np.ndarray) and G.ndim == 2:\n",
        "                return G\n",
        "    for k, v in region.items():\n",
        "        if isinstance(v, np.ndarray) and v.ndim == 2:\n",
        "            return v\n",
        "    raise ValueError(\"No 2D genotype matrix found in region npz.\")\n",
        "\n",
        "\n",
        "def _ensure_snps_by_individuals(G: np.ndarray) -> np.ndarray:\n",
        "    if G.shape[0] < G.shape[1]:\n",
        "        return G.T\n",
        "    return G\n",
        "\n",
        "regions = {}\n",
        "ceu_control_idx = {}\n",
        "case_pool_idx = {}\n",
        "\n",
        "for region_tag, paths in REGION_FILES.items():\n",
        "    regions[region_tag] = {\n",
        "        \"ceu\": load_region_npz(paths[\"ceu\"]),\n",
        "        \"case\": load_region_npz(paths[\"case\"]),\n",
        "    }\n",
        "    ceu_control_idx[region_tag] = load_indices_npz(paths[\"ceu_control_npz\"])\n",
        "    n_case = len(regions[region_tag][\"case\"][\"sample_ids\"])\n",
        "    case_pool_idx[region_tag] = list(range(n_case))\n",
        "\n",
        "    print(f\"Loaded {region_tag} CEU: {paths['ceu'].relative_to(PROJECT_ROOT)}\")\n",
        "    print(f\"Loaded {region_tag} CASE: {paths['case'].relative_to(PROJECT_ROOT)}\")\n",
        "    print(f\"CEU control idx count: {len(ceu_control_idx[region_tag])} | CASE pool: {len(case_pool_idx[region_tag])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def compute_counts_and_maf(G_snps_x_ind: np.ndarray, cols: List[int]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    sub = G_snps_x_ind[:, cols]\n",
        "    called = sub != -1\n",
        "    called_n = called.sum(axis=1).astype(np.int32)\n",
        "    sub_nonmiss = np.where(called, sub, 0)\n",
        "    mac = sub_nonmiss.sum(axis=1).astype(np.float64)\n",
        "    denom = 2.0 * np.maximum(called_n, 1)\n",
        "    maf = mac / denom\n",
        "    return called_n, mac, maf\n",
        "\n",
        "def noisy_counts_from_maf(maf: np.ndarray, called_n: np.ndarray) -> np.ndarray:\n",
        "    raw = np.rint(maf * (2.0 * called_n))\n",
        "    return np.clip(raw, 0.0, 2.0 * called_n).astype(np.float64)\n",
        "\n",
        "def chisq_pvalues_case_vs_control(mac_case: np.ndarray, called_case: np.ndarray,\n",
        "                                 mac_ctrl: np.ndarray, called_ctrl: np.ndarray) -> np.ndarray:\n",
        "    n = mac_case.shape[0]\n",
        "    pvals = np.ones(n, dtype=np.float64)\n",
        "    for j in range(n):\n",
        "        minor_case = mac_case[j]\n",
        "        major_case = 2.0 * called_case[j] - minor_case\n",
        "        minor_ctrl = mac_ctrl[j]\n",
        "        major_ctrl = 2.0 * called_ctrl[j] - minor_ctrl\n",
        "        if called_case[j] <= 0 or called_ctrl[j] <= 0:\n",
        "            pvals[j] = 1.0\n",
        "            continue\n",
        "        if major_case < 0 or major_ctrl < 0:\n",
        "            pvals[j] = 1.0\n",
        "            continue\n",
        "        table = np.array([[minor_case, major_case], [minor_ctrl, major_ctrl]], dtype=np.float64)\n",
        "        if np.any(table.sum(axis=1) <= 0) or np.any(table.sum(axis=0) <= 0):\n",
        "            pvals[j] = 1.0\n",
        "            continue\n",
        "        try:\n",
        "            _, p, _, _ = chi2_contingency(table, correction=False)\n",
        "            pvals[j] = float(p)\n",
        "        except Exception:\n",
        "            pvals[j] = 1.0\n",
        "    return pvals\n",
        "\n",
        "def overlap_metrics(sig_true: np.ndarray, sig_noisy: np.ndarray) -> Dict[str, float]:\n",
        "    a = sig_true.astype(bool)\n",
        "    b = sig_noisy.astype(bool)\n",
        "    tp = int(np.sum(a & b))\n",
        "    fp = int(np.sum(~a & b))\n",
        "    fn = int(np.sum(a & ~b))\n",
        "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
        "    jaccard = tp / (tp + fp + fn) if (tp + fp + fn) else 0.0\n",
        "    return {\n",
        "        \"true_sig\": int(np.sum(a)),\n",
        "        \"noisy_sig\": int(np.sum(b)),\n",
        "        \"tp\": tp,\n",
        "        \"precision\": float(precision),\n",
        "        \"recall\": float(recall),\n",
        "        \"jaccard\": float(jaccard),\n",
        "    }\n",
        "\n",
        "def genotype_log_prob_hwe(g: np.ndarray, p: np.ndarray) -> np.ndarray:\n",
        "    p = np.clip(p, P_CLIP, 1.0 - P_CLIP)\n",
        "    q = 1.0 - p\n",
        "    logP0 = 2.0 * np.log(q)\n",
        "    logP1 = np.log(2.0) + np.log(p) + np.log(q)\n",
        "    logP2 = 2.0 * np.log(p)\n",
        "    out = np.zeros_like(p, dtype=np.float64)\n",
        "    out = np.where(g == 0, logP0, out)\n",
        "    out = np.where(g == 1, logP1, out)\n",
        "    out = np.where(g == 2, logP2, out)\n",
        "    return out\n",
        "\n",
        "def lr_scores(G_snps_x_ind: np.ndarray, cols: List[int], p_case: np.ndarray, p_ctrl: np.ndarray) -> np.ndarray:\n",
        "    G = G_snps_x_ind[:, cols]\n",
        "    n_ind = G.shape[1]\n",
        "    scores = np.zeros(n_ind, dtype=np.float64)\n",
        "    for i in range(n_ind):\n",
        "        g = G[:, i]\n",
        "        mask = g >= 0\n",
        "        if not np.any(mask):\n",
        "            continue\n",
        "        log_case = genotype_log_prob_hwe(g[mask], p_case[mask])\n",
        "        log_ctrl = genotype_log_prob_hwe(g[mask], p_ctrl[mask])\n",
        "        scores[i] = float(np.sum(log_case - log_ctrl))\n",
        "    return scores\n",
        "\n",
        "def split_train_test(indices: List[int], seed: int, frac_train: float = 0.7) -> Tuple[List[int], List[int]]:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    shuffled = list(rng.permutation(indices))\n",
        "    n = len(shuffled)\n",
        "    n_train = int(round(n * frac_train))\n",
        "    n_train = max(1, min(n - 1, n_train))\n",
        "    return shuffled[:n_train], shuffled[n_train:]\n",
        "\n",
        "def grr_probs(eps: float, k: int = 3) -> Tuple[float, float]:\n",
        "    ee = np.exp(eps)\n",
        "    p = ee / (ee + k - 1)\n",
        "    q = (1.0 - p) / (k - 1)\n",
        "    return p, q\n",
        "\n",
        "def ldp_grr_estimate_maf(G_snps_x_ind: np.ndarray, train_idx: List[int], eps: float, rng: np.random.Generator,\n",
        "                         report_k: int = 1, fallback_maf: np.ndarray = None) -> Tuple[np.ndarray, np.ndarray, float, float, int]:\n",
        "\n",
        "    Gsub = G_snps_x_ind[:, train_idx]\n",
        "    n_snps, n_ind = Gsub.shape\n",
        "    p, q = grr_probs(eps, k=3)\n",
        "    counts = np.zeros((n_snps, 3), dtype=np.int32)\n",
        "    report_counts = np.zeros(n_snps, dtype=np.int32)\n",
        "\n",
        "    k = min(report_k, n_snps)\n",
        "    for i in range(n_ind):\n",
        "        snps = rng.choice(n_snps, size=k, replace=False)\n",
        "        for j in snps:\n",
        "            g = int(Gsub[j, i])\n",
        "            if g < 0:\n",
        "                continue\n",
        "            report_counts[j] += 1\n",
        "            if rng.random() < p:\n",
        "                r = g\n",
        "            else:\n",
        "                others = [0, 1, 2]\n",
        "                others.remove(g)\n",
        "                r = others[rng.integers(0, 2)]\n",
        "            counts[j, r] += 1\n",
        "\n",
        "    noisy_maf = np.zeros(n_snps, dtype=np.float64)\n",
        "    zero_reports = 0\n",
        "    for j in range(n_snps):\n",
        "        m = report_counts[j]\n",
        "        if m <= 0:\n",
        "            zero_reports += 1\n",
        "            noisy_maf[j] = fallback_maf[j] if fallback_maf is not None else 0.5\n",
        "            continue\n",
        "        f_hat = counts[j].astype(np.float64) / float(m)\n",
        "        est = (f_hat - q) / (p - q)\n",
        "        est = np.clip(est, 0.0, 1.0)\n",
        "        s = est.sum()\n",
        "        if s <= 0:\n",
        "            est = np.array([1/3, 1/3, 1/3], dtype=np.float64)\n",
        "        else:\n",
        "            est = est / s\n",
        "        noisy_maf[j] = (est[1] + 2.0 * est[2]) / 2.0\n",
        "\n",
        "    noisy_maf = np.clip(noisy_maf, 0.0, 1.0)\n",
        "    return noisy_maf, report_counts, p, q, zero_reports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[chr2_5Mb] n_snps=300 | CEU ctrl=165 | MKK pool=171\n",
            "[chr10_1Mb] n_snps=588 | CEU ctrl=165 | MKK pool=171\n",
            "Saved per-seed table -> results/tables/method3/method3_per_seed_MKK.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Main loop: Method 3 (LDP-GRR)\n",
        "\n",
        "\n",
        "def eps_dir(eps: float) -> Path:\n",
        "    s = str(eps).replace(\".\", \"p\")\n",
        "    return DERIVED_DIR / f\"eps_{s}\"\n",
        "\n",
        "records = []\n",
        "hist_cache = {}\n",
        "\n",
        "for region_tag, region_pair in regions.items():\n",
        "    G_ceu = _ensure_snps_by_individuals(_pick_genotype_matrix(region_pair[\"ceu\"]))\n",
        "    G_case = _ensure_snps_by_individuals(_pick_genotype_matrix(region_pair[\"case\"]))\n",
        "\n",
        "    n_snps, n_ceu = G_ceu.shape\n",
        "    n_snps_case, n_case = G_case.shape\n",
        "    if n_snps != n_snps_case:\n",
        "        raise RuntimeError(f\"SNP count mismatch in {region_tag}: CEU={n_snps}, CASE={n_snps_case}\")\n",
        "\n",
        "    ceu_ctrl_idx = [i for i in ceu_control_idx[region_tag] if i < n_ceu]\n",
        "    case_pool = [i for i in case_pool_idx[region_tag] if i < n_case]\n",
        "\n",
        "    if len(ceu_ctrl_idx) == 0:\n",
        "        raise RuntimeError(f\"No CEU control indices for {region_tag}\")\n",
        "    if len(case_pool) == 0:\n",
        "        raise RuntimeError(f\"No CASE_POP indices for {region_tag}\")\n",
        "\n",
        "    print(f\"[{region_tag}] n_snps={n_snps} | CEU ctrl={len(ceu_ctrl_idx)} | {CASE_POP} pool={len(case_pool)}\")\n",
        "\n",
        "    # Control MAF \n",
        "    called_ctrl, mac_ctrl, maf_ctrl = compute_counts_and_maf(G_ceu, ceu_ctrl_idx)\n",
        "\n",
        "    for eps in EPS_LIST:\n",
        "        outdir = eps_dir(eps)\n",
        "        outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for seed in SEED_LIST:\n",
        "            rng = np.random.default_rng(seed)\n",
        "            case_train_idx, case_test_idx = split_train_test(case_pool, seed=seed, frac_train=0.7)\n",
        "\n",
        "            # True case from CASE train\n",
        "            called_case, mac_case, maf_case = compute_counts_and_maf(G_case, case_train_idx)\n",
        "\n",
        "            # LDP-GRR release\n",
        "            noisy_maf, report_counts, p_grr, q_grr, zero_reports = ldp_grr_estimate_maf(\n",
        "                G_case, case_train_idx, eps, rng, report_k=REPORT_K, fallback_maf=maf_ctrl\n",
        "            )\n",
        "            noisy_mac_safe = noisy_counts_from_maf(noisy_maf, called_case)\n",
        "\n",
        "            # Privacy: LR scores within CASE_POP\n",
        "            scores_member = lr_scores(G_case, case_train_idx, p_case=noisy_maf, p_ctrl=maf_ctrl)\n",
        "            scores_nonmember = lr_scores(G_case, case_test_idx, p_case=noisy_maf, p_ctrl=maf_ctrl)\n",
        "            thresh = float(np.quantile(scores_nonmember, 1.0 - ALPHA_TEST_EXCEED))\n",
        "            lr_power = float(np.mean(scores_member >= thresh))\n",
        "\n",
        "            # Utility: GWAS overlap (true vs noisy)\n",
        "            p_true = chisq_pvalues_case_vs_control(mac_case, called_case, mac_ctrl, called_ctrl)\n",
        "            p_noisy = chisq_pvalues_case_vs_control(noisy_mac_safe, called_case, mac_ctrl, called_ctrl)\n",
        "            sig_true = p_true <= PVALUE_CUTOFF\n",
        "            sig_noisy = p_noisy <= PVALUE_CUTOFF\n",
        "            ov = overlap_metrics(sig_true, sig_noisy)\n",
        "\n",
        "            rmse = float(np.sqrt(np.mean((noisy_maf - maf_case) ** 2)))\n",
        "            maf_mae = float(np.mean(np.abs(noisy_maf - maf_case)))\n",
        "            corr = float(np.corrcoef(noisy_maf, maf_case)[0, 1]) if noisy_maf.size > 1 else 0.0\n",
        "\n",
        "            \n",
        "            seed_dir = outdir / f\"seed_{seed}\"\n",
        "            seed_dir.mkdir(parents=True, exist_ok=True)\n",
        "            out_path = seed_dir / f\"{region_tag}.case_maf_ldp_{CASE_POP}.npz\"\n",
        "            np.savez_compressed(\n",
        "                out_path,\n",
        "                noisy_maf=noisy_maf,\n",
        "                noisy_mac_safe=noisy_mac_safe,\n",
        "                eps=float(eps),\n",
        "                seed=int(seed),\n",
        "                region_tag=region_tag,\n",
        "                case_pop=CASE_POP,\n",
        "                report_k=int(REPORT_K),\n",
        "                p_grr=float(p_grr),\n",
        "                q_grr=float(q_grr),\n",
        "                zero_reports=int(zero_reports),\n",
        "                report_counts=report_counts,\n",
        "                case_train_idx=np.array(case_train_idx, dtype=np.int32),\n",
        "                case_test_idx=np.array(case_test_idx, dtype=np.int32),\n",
        "            )\n",
        "\n",
        "            \n",
        "            if abs(eps - 1.0) < 1e-9 and seed == 0:\n",
        "                hist_cache[region_tag] = (scores_member, scores_nonmember, thresh)\n",
        "\n",
        "            rec = {\n",
        "                \"seed\": int(seed),\n",
        "                \"eps\": float(eps),\n",
        "                \"region\": region_tag,\n",
        "                \"case_pop\": CASE_POP,\n",
        "                \"n_snps\": int(n_snps),\n",
        "                \"n_train\": int(len(case_train_idx)),\n",
        "                \"n_test\": int(len(case_test_idx)),\n",
        "                \"n_ctrl\": int(len(ceu_ctrl_idx)),\n",
        "                \"report_k\": int(REPORT_K),\n",
        "                \"zero_reports\": int(zero_reports),\n",
        "                # privacy\n",
        "                \"lr_threshold_test_95pct\": thresh,\n",
        "                \"lr_power\": lr_power,\n",
        "                \"lr_member_mean\": float(np.mean(scores_member)),\n",
        "                \"lr_nonmember_mean\": float(np.mean(scores_nonmember)),\n",
        "                # utility\n",
        "                **ov,\n",
        "                \"maf_mae\": maf_mae,\n",
        "                \"rmse_maf\": rmse,\n",
        "                \"corr_maf\": corr,\n",
        "            }\n",
        "            records.append(rec)\n",
        "\n",
        "df_per_seed = pd.DataFrame(records)\n",
        "df_per_seed = df_per_seed.sort_values([\"region\", \"eps\", \"seed\"]).reset_index(drop=True)\n",
        "\n",
        "per_seed_csv = TABLE_DIR / f\"method3_per_seed_{CASE_POP}.csv\"\n",
        "df_per_seed.to_csv(per_seed_csv, index=False)\n",
        "print(\"Saved per-seed table ->\", per_seed_csv.relative_to(PROJECT_ROOT))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved summary table -> results/tables/method3/method3_summary_MKK.csv\n",
            "Plots saved under results/figures/method3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Aggregate summary + plots\n",
        "\n",
        "\n",
        "group_cols = [\"region\", \"eps\"]\n",
        "agg_cols = [\"lr_power\", \"jaccard\", \"maf_mae\", \"rmse_maf\", \"corr_maf\", \"true_sig\", \"noisy_sig\"]\n",
        "\n",
        "summary = df_per_seed.groupby(group_cols)[agg_cols].agg([\"mean\", \"std\"]).reset_index()\n",
        "summary.columns = [c[0] if c[1] == \"\" else f\"{c[0]}_{c[1]}\" for c in summary.columns.to_flat_index()]\n",
        "\n",
        "summary_csv = TABLE_DIR / f\"method3_summary_{CASE_POP}.csv\"\n",
        "summary.to_csv(summary_csv, index=False)\n",
        "print(\"Saved summary table ->\", summary_csv.relative_to(PROJECT_ROOT))\n",
        "\n",
        "for region_tag in summary[\"region\"].unique():\n",
        "    sub = summary[summary[\"region\"] == region_tag].sort_values(\"eps\")\n",
        "    eps = sub[\"eps\"].to_numpy()\n",
        "\n",
        "    # Privacy curve\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(eps, sub[\"lr_power_mean\"], marker=\"o\", label=\"LR power\")\n",
        "    plt.xscale(\"log\")\n",
        "    plt.xlabel(\"epsilon (log scale)\")\n",
        "    plt.ylabel(\"LR power (members above 95% nonmember threshold)\")\n",
        "    plt.title(f\"Method 3 Privacy (LR power) — {region_tag}\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIG_DIR / f\"{region_tag}.privacy_lr_power_{CASE_POP}.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Utility curve\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(eps, sub[\"jaccard_mean\"], marker=\"o\", label=\"Jaccard\")\n",
        "    plt.xscale(\"log\")\n",
        "    plt.xlabel(\"epsilon (log scale)\")\n",
        "    plt.ylabel(\"Jaccard(sig_true, sig_noisy)\")\n",
        "    plt.title(f\"Method 3 Utility (GWAS overlap) — {region_tag}\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIG_DIR / f\"{region_tag}.utility_jaccard_{CASE_POP}.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # DP distortion curve\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(eps, sub[\"maf_mae_mean\"], marker=\"o\", label=\"MAF MAE\")\n",
        "    plt.xscale(\"log\")\n",
        "    plt.xlabel(\"epsilon (log scale)\")\n",
        "    plt.ylabel(\"MAF MAE\")\n",
        "    plt.title(f\"Method 3 DP Distortion — {region_tag}\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIG_DIR / f\"{region_tag}.dp_distortion_{CASE_POP}.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # LR histogram for eps=1.0 seed=0\n",
        "    if region_tag in hist_cache:\n",
        "        scores_member, scores_nonmember, thresh = hist_cache[region_tag]\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.hist(scores_member, bins=25, alpha=0.6, label=f\"{CASE_POP} train (members)\")\n",
        "        plt.hist(scores_nonmember, bins=25, alpha=0.6, label=f\"{CASE_POP} test (nonmembers)\")\n",
        "        plt.axvline(thresh, color=\"k\", linestyle=\"--\", linewidth=1, label=\"95% nonmember threshold\")\n",
        "        plt.xlabel(\"LR score\")\n",
        "        plt.ylabel(\"count\")\n",
        "        plt.title(f\"LR score distributions — {region_tag} (eps=1.0)\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(FIG_DIR / f\"{region_tag}.lr_hist_eps_1p0_{CASE_POP}.png\")\n",
        "        plt.close()\n",
        "\n",
        "print(\"Plots saved under\", FIG_DIR.relative_to(PROJECT_ROOT))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
